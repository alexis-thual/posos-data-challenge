{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Notebook\n",
    "This notebook is intended to present models which are loaded from other files as well as the results they allow us to reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gensim\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CATEGORIES = 52\n",
    "PADDING = 150\n",
    "\n",
    "dataFolder = './../posos-data-challenge/challenge_data'\n",
    "xPath = os.path.join(dataFolder, 'input_train.csv')\n",
    "yPath = os.path.join(\n",
    "    dataFolder, 'challenge_output_data_training_file_predict_the_expected_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel():\n",
    "    '''Generic workflow class.'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.verbose = kwargs.get('verbose', False)\n",
    "\n",
    "        self.nbCategories = kwargs['nbCategories']\n",
    "        self.paddingLength = PADDING\n",
    "        self.maxNumberWords = (1e5)\n",
    "        self.trainable = kwargs.get('trainable', False)\n",
    "\n",
    "        self.tokenizer = text.Tokenizer(num_words=self.maxNumberWords)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        '''Turns sentences into padded word sequences.'''\n",
    "\n",
    "        self.tokenizer.fit_on_texts(x)\n",
    "        sequences = self.tokenizer.texts_to_sequences(x)\n",
    "        sequences = sequence.pad_sequences(sequences, self.paddingLength)\n",
    "\n",
    "        return sequences\n",
    "\n",
    "    def preprocessLabels(self, labels):\n",
    "        return to_categorical(labels, num_classes=self.nbCategories)\n",
    "\n",
    "    def train(self, x, y, epochs= 10, batch_size=32, validation_data=None,\n",
    "              callback=False):\n",
    "        if callback == True:\n",
    "            filepath= 'models_checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_acc',\n",
    "                                         verbose=1, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data,\n",
    "                           callbacks=callbacks_list)\n",
    "        else:\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        return self.model.evaluate(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize generic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform spelling corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctionsPath = os.path.join(dataFolder, 'corrections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def spellingCorrection(self, x, correct_dict={}, verbose=False):\n",
    "        corrected_x = []\n",
    "        for w in x.split():\n",
    "            if w in correct_dict.keys():\n",
    "                w_corrected = corrected_dict[w]\n",
    "                if verbose == True:\n",
    "                    print('Correction of ' + w + ' in ' + w_corrected)\n",
    "                w = w_corrected\n",
    "            corrected_x.append(w)\n",
    "        return ' '.join(corrected_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differenciate medics from other words\n",
    "We here use a list of medication names to distinguish better between common words and specialized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste de médicaments regroupant les libéllés ATC et lesdénominations de spécialité, de taille: 8275\n",
      "Sample of medicament names:  ['ubistesin adrenalinee', 'forene,', 'sevorane,', 'chirocaïne', 'duodopa', 'synagis', 'kaletra', 'humira', 'norvir', 'viekirax']\n"
     ]
    }
   ],
   "source": [
    "MEDICAMENTS = []\n",
    "medicsPath = os.path.join(dataFolder, 'medicaments_france.xls')\n",
    "medic_db = pd.read_excel(medicsPath)\n",
    "\n",
    "for m in medic_db['Dénomination spécialité']:\n",
    "    med = []\n",
    "    for w in m.split():\n",
    "        if w.lower()!=w:\n",
    "            med.append(w)\n",
    "    med = ' '.join(med)\n",
    "    if len(med)!=0:\n",
    "        med = med.lower()\n",
    "        if med not in MEDICAMENTS:\n",
    "            MEDICAMENTS.append(med.lower())\n",
    "\n",
    "for m in medic_db['Libellé ATC']:\n",
    "    med = m.split()[0].lower()\n",
    "    if med not in MEDICAMENTS:\n",
    "        MEDICAMENTS.append(med)\n",
    "\n",
    "print('Liste de médicaments regroupant les libéllés ATC et les'\n",
    "      'dénominations de spécialité, de taille: {}'.format(len(MEDICAMENTS)))\n",
    "print('Sample of medicament names: ', MEDICAMENTS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.medicaments = kwargs['medicaments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import Input, Conv1D, Dense, Dropout, GlobalMaxPooling1D\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildCNN1D(self, embedding, drop_rate=0.3, nb_filters=128,\n",
    "                   filter_size=4, padding = PADDING):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = keras.Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = (Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding'))(my_input)\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "\n",
    "        conv1 = Conv1D(nb_filters, filter_size,\n",
    "                       activation='relu', name='conv1')(embedding_dropped)\n",
    "        pooled1 = GlobalMaxPooling1D(name='pool1')(conv1)\n",
    "        dropped1 = Dropout(drop_rate, name='drop1')(pooled1)\n",
    "        dense1 = Dense(self.nbCategories, activation = 'relu', name = 'dense1')(dropped1)\n",
    "        \n",
    "        prob = Dense(self.nbCategories, activation='softmax', name='softmax')(dense1)\n",
    "        \n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import LSTM, Embedding, Dropout\n",
    "\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def buildLSTM(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=3):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = Embedding(input_length=self.paddingLength,\n",
    "                                input_dim=self.embedding.shape[0],\n",
    "                                output_dim=self.embedding.shape[1],\n",
    "                                weights=[self.embedding],\n",
    "                                trainable=self.trainable,\n",
    "                                name='embedding')(my_input)\n",
    "\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "#         CNN cell\n",
    "#         conv1 = Conv1D(nb_filters, filter_size, activation='relu', name='conv1',\n",
    "#                        padding = 'same')(embedding_dropped)\n",
    "#         pooled_conv1 = MaxPooling1D(pool_size = 2, name = 'pool1')(conv1)\n",
    "#         dropped1 = Dropout(drop_rate, name = 'drop1')(pooled_conv1)\n",
    "        lstm1 = LSTM(100, name = 'lstm1', dropout= drop_rate,\n",
    "                     recurrent_dropout= drop_rate)(embedding_dropped)\n",
    "        dense1 = Dense(self.nbCategories, activation = 'relu', name = 'dense1')(lstm1)\n",
    "        prob = Dense(self.nbCategories, activation='softmax', name='softmax')(dense1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement a 2D convnet for text classification: \n",
    "#inspired from : https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import MaxPooling1D, LSTM, Conv1D\n",
    "\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def buildLSTM_CNN(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=3):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = Embedding(input_length=self.paddingLength,\n",
    "                                input_dim=self.embedding.shape[0],\n",
    "                                output_dim=self.embedding.shape[1],\n",
    "                                weights=[self.embedding],\n",
    "                                trainable=self.trainable,\n",
    "                                name='embedding')(my_input)\n",
    "\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "        conv1 = Conv1D(nb_filters, filter_size, activation='relu',\n",
    "                       name='conv1', padding='same')(embedding_dropped)\n",
    "        pooled1 = MaxPooling1D(pool_size = 2, name = 'pool1')(conv1)\n",
    "        dropped1 = Dropout(drop_rate, name = 'drop1')(pooled1)\n",
    "        lstm1 = LSTM(100, name = 'lstm1',\n",
    "                     dropout= drop_rate, recurrent_dropout= drop_rate)(dropped1)\n",
    "        prob = Dense(self.nbCategories,\n",
    "                     activation='softmax', name='dense1')(lstm1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# implement a 2D convnet for text classification: \n",
    "#inspiration is here : http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import (Input, Conv2D, Dense, Dropout,\n",
    "                          MaxPooling2D, Flatten, Concatenate, Reshape)\n",
    "\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildCNN2D(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=[3, 5, 8],\n",
    "                   padding=PADDING):\n",
    "        if np.isscalar(filter_size):\n",
    "            filter_size = [3, 5, 8]\n",
    "            print(\"WARNING: You have to enter a list for the different\\\n",
    "            filter sizes, we modified directly to: {}\".format(filter_size))\n",
    "        \n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = Input(shape=(self.paddingLength, ), name= 'input')\n",
    "\n",
    "        embedding = Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding')(my_input)\n",
    "        embedding = Reshape((padding, self.embedding.shape[1], 1))(embedding)\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "        \n",
    "        # we concatenate 3 filter sizes\n",
    "        conv0 = Conv2D(nb_filters, (filter_size[0], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv0', padding='valid')(embedding_dropped)\n",
    "        pooled0 = MaxPooling2D(pool_size=(padding - filter_size[0] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool0')(conv0)\n",
    "        \n",
    "        conv1 = Conv2D(nb_filters, (filter_size[1], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv1', padding='valid')(embedding_dropped)\n",
    "        pooled1 = MaxPooling2D(pool_size = (padding - filter_size[1] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool1')(conv1)\n",
    "        \n",
    "        conv2 = Conv2D(nb_filters, (filter_size[2], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv2', padding='valid')(embedding_dropped)\n",
    "        pooled2 = MaxPooling2D(pool_size = (padding - filter_size[2] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool2')(conv2)\n",
    "        \n",
    "        concatenated = Concatenate(axis = 1)([pooled0, pooled1, pooled2])\n",
    "        flattened = keras.layers.Flatten()(concatenated)\n",
    "        dropped1 = Dropout(drop_rate, name='drop1')(flattened)  \n",
    "        prob = Dense(self.nbCategories, activation='softmax', name='dense2')(dropped1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model variables\n",
    "TRAINABLE = False # never train the embedding for the classification task (overfitting)\n",
    "PRE_TRAINED_DIM = 300 # Size of the pretrained embedding used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instance creation\n",
    "model = CustomModel(nbCategories=NB_CATEGORIES, trainable=TRAINABLE, medicaments=MEDICAMENTS)\n",
    "\n",
    "# Loading, parsing and spliting training and testing data\n",
    "x = pd.read_csv(xPath, delimiter=';', usecols=[1]).values.ravel()\n",
    "y = pd.read_csv(yPath, delimiter=';', usecols=[1]).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling mistakes\n",
    "corrected_dict = {}\n",
    "for key, val in csv.reader(open(correctionsPath)):\n",
    "    corrected_dict[key] = val\n",
    "for i, s in enumerate(x):\n",
    "    x[i] = model.spellingCorrection(s, corrected_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  10141\n"
     ]
    }
   ],
   "source": [
    "# Print some info about our vocabulary\n",
    "model.preprocess(x)\n",
    "x_vocab  = list(model.tokenizer.word_index.keys())\n",
    "print('Vocabulary size: ', len(x_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Embedding Created ----------\n",
      "Number of words in corpus that do not appear in pretrained Fasttext:  2760\n"
     ]
    }
   ],
   "source": [
    "# Loading and using pretrained embedding\n",
    "\n",
    "# Using fasttext\n",
    "path2embedding = '../wiki.fr.vec'\n",
    "# using fasttext trained on wiki_fr and emea database\n",
    "# path2embedding = '../word_embeddings/retrained_fr.vec'\n",
    "pre_trained_wv = gensim.models.KeyedVectors.load_word2vec_format(path2embedding,\n",
    "                                                                 binary=False)\n",
    "\n",
    "# We use an embedding size of len(x_vocab) + 1 because the 0 is used for the padding\n",
    "embeddings = np.zeros((len(x_vocab) + 1 , PRE_TRAINED_DIM))\n",
    "not_in_pretrained = []\n",
    "\n",
    "for word, idx in model.tokenizer.word_index.items():\n",
    "    if word not in pre_trained_wv.vocab:\n",
    "        vec = np.zeros(PRE_TRAINED_DIM)\n",
    "        not_in_pretrained.append(word)\n",
    "    else:\n",
    "        vec = pre_trained_wv[word]\n",
    "\n",
    "    # word_to_index is 1-based! the 0-th row, used for padding, stays at zero\n",
    "    embeddings[idx,] = vec\n",
    "\n",
    "print('---------- Embedding Created ----------')\n",
    "print('Number of words in corpus that do not appear in '\n",
    "      'pretrained Fasttext: ', len(not_in_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the embedding for convenience\n",
    "#np.save('challenge_data/fasttext_voc_not_corrected.npy', embeddings)\n",
    "#np.save('challenge_data/fasttext_emb.npy', embeddings)\n",
    "np.save('challenge_data/fasttext_retrained.npy', embeddings)\n",
    "#embeddings = np.load('challenge_data/fasttext_emb.npy')\n",
    "#embeddings = np.load('challenge_data/fasttext_voc_not_corrected.npy')\n",
    "embeddings = np.load('challenge_data/fasttext_retrained.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/util/deprecation.py:497: calling conv1d (from tensorflow.python.ops.nn_ops) with data_format=NHWC is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "`NHWC` for data_format is deprecated, use `NWC` instead\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 300)          3042600   \n",
      "_________________________________________________________________\n",
      "drop0 (Dropout)              (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 150, 256)          230656    \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling1D)         (None, 75, 256)           0         \n",
      "_________________________________________________________________\n",
      "drop1 (Dropout)              (None, 75, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 100)               142800    \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 52)                5252      \n",
      "=================================================================\n",
      "Total params: 3,421,308\n",
      "Trainable params: 378,708\n",
      "Non-trainable params: 3,042,600\n",
      "_________________________________________________________________\n",
      "Total number of model parameters: 3421308\n"
     ]
    }
   ],
   "source": [
    "# Model parameters among (drop_rate=0.3, nb_filters=32, filter_size=3)\n",
    "DROP_RATE = 0.3\n",
    "NB_FILTERS = 256\n",
    "FILTER_SIZE = 3\n",
    "#FILTERS_SIZES = []\n",
    "# Build our model\n",
    "model.buildLSTM_CNN(embeddings, drop_rate=DROP_RATE, nb_filters=NB_FILTERS,\n",
    "                    filter_size=FILTER_SIZE)\n",
    "model.model.summary()\n",
    "\n",
    "print('Total number of model parameters:', model.model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data and labels before training\n",
    "y = model.preprocessLabels(y)\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xTrain = model.preprocess(xTrain)\n",
    "xTest = model.preprocess(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 25s 4ms/step - loss: 3.1205 - acc: 0.2448 - val_loss: 2.8593 - val_acc: 0.2989\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 29s 4ms/step - loss: 2.7276 - acc: 0.3248 - val_loss: 2.7072 - val_acc: 0.3200\n",
      "Epoch 3/10\n",
      "6422/6422 [==============================] - 29s 5ms/step - loss: 2.4569 - acc: 0.3792 - val_loss: 2.6589 - val_acc: 0.3362\n",
      "Epoch 4/10\n",
      "6422/6422 [==============================] - 28s 4ms/step - loss: 2.2295 - acc: 0.4413 - val_loss: 2.6847 - val_acc: 0.3300\n",
      "Epoch 5/10\n",
      "6422/6422 [==============================] - 32s 5ms/step - loss: 2.0787 - acc: 0.4707 - val_loss: 2.7109 - val_acc: 0.3418\n",
      "Epoch 6/10\n",
      "6422/6422 [==============================] - 31s 5ms/step - loss: 1.9311 - acc: 0.5020 - val_loss: 2.7393 - val_acc: 0.3431\n",
      "Epoch 7/10\n",
      "6422/6422 [==============================] - 32s 5ms/step - loss: 1.8150 - acc: 0.5268 - val_loss: 2.7047 - val_acc: 0.3462\n",
      "Epoch 8/10\n",
      "6422/6422 [==============================] - 28s 4ms/step - loss: 1.7253 - acc: 0.5461 - val_loss: 2.7937 - val_acc: 0.3300\n",
      "Epoch 9/10\n",
      "6422/6422 [==============================] - 29s 4ms/step - loss: 1.6286 - acc: 0.5740 - val_loss: 2.8109 - val_acc: 0.3269\n",
      "Epoch 10/10\n",
      "6422/6422 [==============================] - 29s 5ms/step - loss: 1.5380 - acc: 0.5925 - val_loss: 2.7969 - val_acc: 0.3468\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "model.train(xTrain, yTrain, epochs=EPOCHS, batch_size= BATCH_SIZE,\n",
    "            validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606/1606 [==============================] - 2s 1ms/step\n",
      "Accuracy: 34.68 %\n",
      "Loss: [2.796889444068538, 0.3468244084682441]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(xTest, yTest)\n",
    "\n",
    "prediction = model.predict(xTest)\n",
    "predictionCategories = np.argmax(prediction, axis=1)\n",
    "yTestCategories = np.argmax(yTest, axis=1)\n",
    "accuracy = 100 * sum([predictionCategories[i] == yTestCategories[i]\n",
    "                      for i in range(len(yTestCategories))]) / len(yTestCategories)\n",
    "\n",
    "print('Accuracy: {:.2f} %\\nLoss: {}'.format(accuracy, str(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPosition = np.arange(NB_CATEGORIES)\n",
    "\n",
    "c = collections.Counter(yTestCategories)\n",
    "od = collections.OrderedDict(sorted(c.items(), key=lambda x: x[0]))\n",
    "cp = collections.Counter(predictionCategories)\n",
    "odp = collections.OrderedDict(sorted(cp.items(), key=lambda x: x[0]))\n",
    "\n",
    "correctResults = predictionCategories[predictionCategories == yTestCategories]\n",
    "cc = collections.Counter(correctResults)\n",
    "odc = collections.OrderedDict(sorted(cc.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod = np.zeros(NB_CATEGORIES)\n",
    "for key in od:\n",
    "    pod[key] = od[key]\n",
    "\n",
    "podp = np.zeros(NB_CATEGORIES)\n",
    "for key in odp:\n",
    "    podp[key] = odp[key]\n",
    "\n",
    "podc = np.zeros(NB_CATEGORIES)\n",
    "for key in odc:\n",
    "    podc[key] = odc[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd920e63160>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(yPosition, pod, alpha=0.5)\n",
    "plt.bar(yPosition, podp, alpha=0.5)\n",
    "plt.bar(yPosition, podc, alpha=0.5)\n",
    "\n",
    "plt.ylabel('Unique count')\n",
    "plt.title('Categories')\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAEyCAYAAACLaSO4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRNwAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fad66937e48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.hist(y, bins=NB_CATEGORIES, label='train labels', density=True, alpha=1)\n",
    "plt.hist(predictionCategories, bins=NB_CATEGORIES,\n",
    "         label='predicted labels', density=True, alpha=0.6)\n",
    "plt.axis\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 44, 44, ..., 48, 45, 44])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTestCategories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
