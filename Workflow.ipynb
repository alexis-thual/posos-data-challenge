{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Notebook\n",
    "This notebook is intended to present models which are loaded from other files as well as the results they allow us to reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import gensim\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers import (Input, Conv1D, Dense, Dropout,\n",
    "                          GlobalMaxPooling1D, GlobalMaxPooling2D)\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CATEGORIES = 52\n",
    "BATCHSIZE = 32\n",
    "\n",
    "dataFolder = './../posos-data-challenge/challenge_data'\n",
    "xPath = os.path.join(dataFolder, 'input_train.csv')\n",
    "yPath = os.path.join(\n",
    "    dataFolder, 'challenge_output_data_training_file_predict_the_expected_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel():\n",
    "    '''Generic workflow class.'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.verbose = kwargs.get('verbose', False)\n",
    "\n",
    "        self.nbCategories = kwargs['nbCategories']\n",
    "        self.paddingLength = PADDING\n",
    "        self.maxNumberWords = (1e5)\n",
    "        self.trainable = kwargs.get('trainable', False)\n",
    "\n",
    "        self.tokenizer = text.Tokenizer(num_words=self.maxNumberWords)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        '''Turns sentences into padded word sequences.'''\n",
    "\n",
    "        self.tokenizer.fit_on_texts(x)\n",
    "        sequences = self.tokenizer.texts_to_sequences(x)\n",
    "        sequences = sequence.pad_sequences(sequences, self.paddingLength)\n",
    "\n",
    "        return sequences\n",
    "\n",
    "    def preprocessLabels(self, labels):\n",
    "        return to_categorical(labels, num_classes=self.nbCategories)\n",
    "\n",
    "    def train(self, x, y, epochs=5, batch_size=BATCHSIZE, validation_data=None,\n",
    "              callback=False):\n",
    "        if callback == True:\n",
    "            filepath= 'models_checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_acc',\n",
    "                                         verbose=1, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data,\n",
    "                           callbacks=callbacks_list)\n",
    "        else:\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        return self.model.evaluate(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize generic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform spelling corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctionsPath = os.path.join(dataFolder, 'corrections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def spellingCorrection(self, x, correct_dict={}, verbose=False):\n",
    "        corrected_x = []\n",
    "        for w in x.split():\n",
    "            if w in correct_dict.keys():\n",
    "                w_corrected = corrected_dict[w]\n",
    "                if verbose == True:\n",
    "                    print('Correction of ' + w + ' in ' + w_corrected)\n",
    "                w = w_corrected\n",
    "            corrected_x.append(w)\n",
    "        return ' '.join(corrected_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differenciate medics from other words\n",
    "We here use a list of medication names to distinguish better between common words and specialized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste de médicaments regroupant les libéllés ATC et lesdénominations de spécialité, de taille: 8275\n",
      "Sample of medicament names:  ['ubistesin adrenalinee', 'forene,', 'sevorane,', 'chirocaïne', 'duodopa', 'synagis', 'kaletra', 'humira', 'norvir', 'viekirax']\n"
     ]
    }
   ],
   "source": [
    "MEDICAMENTS = []\n",
    "medicsPath = os.path.join(dataFolder, 'medicaments_france.xls')\n",
    "medic_db = pd.read_excel(medicsPath)\n",
    "\n",
    "for m in medic_db['Dénomination spécialité']:\n",
    "    med = []\n",
    "    for w in m.split():\n",
    "        if w.lower()!=w:\n",
    "            med.append(w)\n",
    "    med = ' '.join(med)\n",
    "    if len(med)!=0:\n",
    "        med = med.lower()\n",
    "        if med not in MEDICAMENTS:\n",
    "            MEDICAMENTS.append(med.lower())\n",
    "\n",
    "for m in medic_db['Libellé ATC']:\n",
    "    med = m.split()[0].lower()\n",
    "    if med not in MEDICAMENTS:\n",
    "        MEDICAMENTS.append(med)\n",
    "\n",
    "print('Liste de médicaments regroupant les libéllés ATC et les'\n",
    "      'dénominations de spécialité, de taille: {}'.format(len(MEDICAMENTS)))\n",
    "print('Sample of medicament names: ', MEDICAMENTS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.medicaments = kwargs['medicaments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildModel(self, embedding, drop_rate=0.5, nb_filters=32, filter_size=3):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = keras.Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = (Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding'))(my_input)\n",
    "\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop1')(embedding)\n",
    "\n",
    "        conv1 = Conv1D(nb_filters, filter_size,\n",
    "                      activation='relu', name='conv1')(embedding_dropped)\n",
    "        pooled_conv1 = GlobalMaxPooling1D(name='pool1')(conv1)\n",
    "        pooled_conv_dropped1 = Dropout(drop_rate, name='drop2')(pooled_conv1)\n",
    "        \n",
    "        dense1 = Dense(100, activation='relu', name='dense1')(pooled_conv_dropped1)\n",
    "        dropout2 = Dropout(0.1, name='drop3')(dense1)\n",
    "\n",
    "        prob = Dense(self.nbCategories,\n",
    "                     activation='softmax', name='dense2')(dropout2)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model variables\n",
    "TRAINABLE = False\n",
    "PADDING = 150\n",
    "EPOCHS = 10\n",
    "PRE_TRAINED_DIM = 300 # Size of the pretrained embedding used here\n",
    "\n",
    "# Model parameters among (drop_rate=0.5, nb_filters=32, filter_size=3)\n",
    "DROP_RATE = 0.5\n",
    "NB_FILTERS = 100\n",
    "FILTER_SIZE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instance creation\n",
    "model = CustomModel(nbCategories=NB_CATEGORIES, trainable=TRAINABLE, medicaments=MEDICAMENTS)\n",
    "\n",
    "# Loading, parsing and spliting training and testing data\n",
    "x = pd.read_csv(xPath, delimiter=';', usecols=[1]).values.ravel()\n",
    "y = pd.read_csv(yPath, delimiter=';', usecols=[1]).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling mistakes\n",
    "corrected_dict = {}\n",
    "for key, val in csv.reader(open(correctionsPath)):\n",
    "    corrected_dict[key] = val\n",
    "for i, s in enumerate(x):\n",
    "    x[i] = model.spellingCorrection(s, corrected_dict, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  10141\n"
     ]
    }
   ],
   "source": [
    "# Print some info about our vocabulary\n",
    "model.preprocess(x)\n",
    "x_vocab  = list(model.tokenizer.word_index.keys())\n",
    "print('Vocabulary size: ', len(x_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Embedding Created ----------\n",
      "Number of words in corpus that do not appear in pretrained Fasttext:  2760\n"
     ]
    }
   ],
   "source": [
    "# Loading and using pretrained embedding\n",
    "\n",
    "# Using fasttext\n",
    "path2embedding = './../wiki.fr.vec'\n",
    "pre_trained_wv = gensim.models.KeyedVectors.load_word2vec_format(path2embedding,\n",
    "                                                                 binary=False)\n",
    "\n",
    "# We use an embedding size of len(x_vocab) + 1 because the 0 is used for the padding\n",
    "embeddings = np.zeros((len(x_vocab) + 1 , PRE_TRAINED_DIM))\n",
    "not_in_pretrained = []\n",
    "\n",
    "for word, idx in model.tokenizer.word_index.items():\n",
    "    if word not in pre_trained_wv.vocab:\n",
    "        vec = np.zeros(PRE_TRAINED_DIM)\n",
    "        not_in_pretrained.append(word)\n",
    "    else:\n",
    "        vec = pre_trained_wv[word]\n",
    "\n",
    "    # word_to_index is 1-based! the 0-th row, used for padding, stays at zero\n",
    "    embeddings[idx,] = vec\n",
    "\n",
    "print('---------- Embedding Created ----------')\n",
    "print('Number of words in corpus that do not appear in '\n",
    "      'pretrained Fasttext: ', len(not_in_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 300)          3042600   \n",
      "_________________________________________________________________\n",
      "drop1 (Dropout)              (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 148, 100)          90100     \n",
      "_________________________________________________________________\n",
      "pool1 (GlobalMaxPooling1D)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "drop2 (Dropout)              (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "drop3 (Dropout)              (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 52)                5252      \n",
      "=================================================================\n",
      "Total params: 3,148,052\n",
      "Trainable params: 105,452\n",
      "Non-trainable params: 3,042,600\n",
      "_________________________________________________________________\n",
      "Total number of model parameters: 3148052\n"
     ]
    }
   ],
   "source": [
    "# Build our model\n",
    "model.buildModel(embeddings, drop_rate=DROP_RATE,\n",
    "                 nb_filters=NB_FILTERS, filter_size=FILTER_SIZE)\n",
    "model.model.summary()\n",
    "\n",
    "print('Total number of model parameters:', model.model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data and labels before training\n",
    "y = model.preprocessLabels(y)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xTrain = model.preprocess(xTrain)\n",
    "xTest = model.preprocess(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 3.3439 - acc: 0.2104\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 7s 1ms/step - loss: 3.0852 - acc: 0.2562\n",
      "Epoch 3/10\n",
      "3680/6422 [================>.............] - ETA: 3s - loss: 2.9443 - acc: 0.2810"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train(xTrain, yTrain, epochs=EPOCHS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomModel' object has no attribute 'model'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-2f42e3cb900e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0myTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprediction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxTest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mpredictionCategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0myTestCategories\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myTest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-1ab61e868f67>\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y)\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CustomModel' object has no attribute 'model'"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(xTest, yTest)\n",
    "\n",
    "prediction = model.predict(xTest)\n",
    "predictionCategories = np.argmax(prediction, axis=1)\n",
    "yTestCategories = np.argmax(yTest, axis=1)\n",
    "accuracy = 100 * sum([predictionCategories[i] == yTestCategories[i]\n",
    "                      for i in range(len(yTestCategories))]) / len(yTestCategories)\n",
    "\n",
    "print('Accuracy: {:.2f} %\\nLoss: {}'.format(accuracy, str(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f75681633c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.hist(y, bins=NB_CATEGORIES, label='train labels', density=True, alpha=0.6)\n",
    "plt.hist(predictionCategories, bins=NB_CATEGORIES,\n",
    "         label='predicted labels', density=True, alpha=0.6)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 44, 44, ..., 48, 45, 44])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTestCategories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
