{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Notebook\n",
    "This notebook is intended to present models which are loaded from other files as well as the results they allow us to reach. It goes through the following steps:\n",
    "* Defining Global Variables\n",
    "* Loading Word Embeddings\n",
    "* Loading Data\n",
    "* Preprocessing Data\n",
    "    * Correcting Spelling Mistakes\n",
    "    * Spliting Training and Testing Data\n",
    "    * Tokenizing Data\n",
    "    * Building and Refining Embeddings Array\n",
    "* Model definition\n",
    "* Model training\n",
    "* Model testing and evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import gensim\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Global Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_SEED = 42\n",
    "NB_CATEGORIES = 51\n",
    "\n",
    "dataDirPath = './challenge_data'\n",
    "embeddingsDirPath = './../word_embeddings/'\n",
    "xPath = os.path.join(dataDirPath, 'input_train.csv')\n",
    "yPath = os.path.join(dataDirPath, 'output_train.csv')\n",
    "xTestPath = os.path.join(dataDirPath, 'input_test.csv')\n",
    "#embeddingPath = os.path.join(embeddingsDirPath, 'wiki.fr.vec')\n",
    "embeddingPath = os.path.join(embeddingsDirPath, 'retrained_fr.vec')\n",
    "embeddingPath = os.path.join(embeddingsDirPath, 'retrained_questions.vec')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Word Embeddings\n",
    "Load from fasttext or EMEA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-6855946c7206>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpretrainedEmbeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKeyedVectors\u001b[0m\u001b[0;34m.\u001b[0m    \u001b[0mload_word2vec_format\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddingPath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbinary\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/virtualenvs/tensorflow_3.5/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36mload_word2vec_format\u001b[0;34m(cls, fname, fvocab, binary, encoding, unicode_errors, limit, datatype)\u001b[0m\n\u001b[1;32m    252\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"invalid vector on line %s (is this really the text format?)\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mline_no\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    253\u001b[0m                     \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mREAL\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 254\u001b[0;31m                     \u001b[0madd_word\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    255\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m             logger.info(\n",
      "\u001b[0;32m~/virtualenvs/tensorflow_3.5/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36madd_word\u001b[0;34m(word, weights)\u001b[0m\n\u001b[1;32m    216\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mcounts\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m                     \u001b[0;31m# most common scenario: no vocab file given. just make up some bogus counts, in descending order\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m                     \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVocab\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mword_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvocab_size\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mword_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0mword\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcounts\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                     \u001b[0;31m# use count from the vocab file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/virtualenvs/tensorflow_3.5/lib/python3.5/site-packages/gensim/models/keyedvectors.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__dict__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "pretrainedEmbeddings = gensim.models.KeyedVectors.\\\n",
    "    load_word2vec_format(embeddingPath, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = pd.read_csv(xPath, delimiter=';', usecols=[1]).values.ravel()\n",
    "xTest = pd.read_csv(xTestPath, delimiter=';', usecols=[1]).values.ravel()\n",
    "y = pd.read_csv(yPath, delimiter=';', usecols=[1]).values.ravel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Correcting Spelling Mistakes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7973\n"
     ]
    }
   ],
   "source": [
    "correctionsDict = {}\n",
    "correctionsPath = os.path.join(dataDirPath, 'corrections.csv')\n",
    "\n",
    "with open(correctionsPath, 'r') as f:\n",
    "    for key, val in csv.reader(f):\n",
    "        correctionsDict[key] = val\n",
    "\n",
    "def spellingCorrection(sentence, correctionsDict={}, verbose=False):\n",
    "    correctedSentence = []\n",
    "    nb_corrections = 0\n",
    "    for word in sentence.split():\n",
    "        if word in correctionsDict.keys():\n",
    "            word = correctionsDict[word]\n",
    "            nb_corrections += 1\n",
    "        correctedSentence.append(word)\n",
    "    if verbose:\n",
    "        return ' '.join(correctedSentence), nb_corrections\n",
    "    else:\n",
    "        return ' '.join(correctedSentence)\n",
    "\n",
    "nb_corr = 0\n",
    "for i, s in enumerate(x):\n",
    "    cor = spellingCorrection(s, correctionsDict, verbose = True)\n",
    "    x[i] = cor[0]\n",
    "    nb_corr += cor[1]\n",
    "\n",
    "for i, s in enumerate(xTest):\n",
    "    cor = spellingCorrection(s, correctionsDict, verbose = True)\n",
    "    xTest[i] = cor[0]\n",
    "    nb_corr += cor[1]\n",
    "print(nb_corr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text.Tokenizer(\n",
    "    num_words=1e5,\n",
    "    filters=\"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'´’™©®«»\",\n",
    "    split=\" \"\n",
    ")\n",
    "\n",
    "tokenizer.fit_on_texts(np.concatenate((x, xTest)))\n",
    "vocabulary = tokenizer.word_index.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  10175\n"
     ]
    }
   ],
   "source": [
    "print('Vocabulary size: ', len(vocabulary))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parsing Inputs And Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "PADDING = 100\n",
    "\n",
    "x = tokenizer.texts_to_sequences(x)\n",
    "x = sequence.pad_sequences(x, PADDING)\n",
    "xTest = tokenizer.texts_to_sequences(xTest)\n",
    "xTest = sequence.pad_sequences(xTest, PADDING)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spliting Training And Validation Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Downsampling the categories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downsample(x, y, threshold = None, show = False):\n",
    "    nb_categories = len(set(y))\n",
    "    if threshold is None:\n",
    "        countCategories = [0] * nb_categories\n",
    "        for point in y:\n",
    "            countCategories[point] += 1\n",
    "        indexedCountCategories = list(zip(list(range(nb_categories)), countCategories))\n",
    "        selectedCategories = list(filter(lambda x: x[1] > 100, indexedCountCategories))\n",
    "        #threshold = np.percentile([cat[1] for cat in selectedCategories], 75)\n",
    "        threshold = np.mean([cat[1] for cat in selectedCategories])\n",
    "    print('Thresholding each category to {} datapoints.'.format(threshold))\n",
    "    X = []\n",
    "    Y = []\n",
    "    count_categories = np.zeros(nb_categories)\n",
    "    for xx, yy in zip(x, y):\n",
    "        if count_categories[yy] <= threshold:\n",
    "            X.append(xx)\n",
    "            Y.append(yy)\n",
    "            count_categories[yy]+=1\n",
    "    X = np.array(X)\n",
    "    Y = np.array(Y)\n",
    "    if show == True:\n",
    "        plt.figure(figsize=(15, 5))\n",
    "        plt.hist(Y, bins=nb_categories, label='train labels', density=False, alpha=1)\n",
    "        plt.axis\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thresholding each category to 1000 datapoints.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3cAAAEyCAYAAABZOSngAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f046c024080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x, y = downsample(x, y, threshold=1000, show = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y, num_classes=NB_CATEGORIES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "xTrain, xValid, yTrain, yValid = train_test_split(x, y, test_size = 0.2, random_state = RANDOM_SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building And Refining Embedding Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading Medic Names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste de médicaments regroupant les libéllés ATC et lesdénominations de spécialité, de taille: 8390\n",
      "Sample of medicament names:  ['a 313 200  pour cent', 'a 313 50 000 u.i', 'abacavir', 'abacavir/lamivudine', 'abacavir/lamivudine pharma', 'abacavir/lamivudine pharos', 'abamipharm', 'abboticine', 'abelcet', 'abstral']\n"
     ]
    }
   ],
   "source": [
    "MEDICAMENTS = []\n",
    "\n",
    "with open(os.path.join(dataDirPath, 'medicList.txt')) as f:\n",
    "    for line in f:\n",
    "        MEDICAMENTS.append(line.lower().rstrip())\n",
    "\n",
    "print('Liste de médicaments regroupant les libéllés ATC et les'\n",
    "      'dénominations de spécialité, de taille: {}'.format(len(MEDICAMENTS)))\n",
    "print('Sample of medicament names: ', MEDICAMENTS[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use an embedding size of len(x_vocab) + 1 because the 0 is used for the padding\n",
    "PRE_TRAINED_DIM = 300\n",
    "REDUCED_DIM = 100\n",
    "TRAINABLE = True # Training the embedding can lead to overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = np.zeros((len(vocabulary) + 1 , PRE_TRAINED_DIM))\n",
    "not_in_pretrained = []\n",
    "detected_medic = []\n",
    "\n",
    "for word, idx in tokenizer.word_index.items():\n",
    "    if word not in pretrainedEmbeddings.vocab:\n",
    "        unaccented = unidecode(word)\n",
    "        if word in MEDICAMENTS:\n",
    "            vec = pretrainedEmbeddings['médicament']\n",
    "            detected_medic.append(word)\n",
    "        else:\n",
    "            vec = np.zeros(PRE_TRAINED_DIM)\n",
    "            not_in_pretrained.append(word)\n",
    "    else:\n",
    "        vec = pretrainedEmbeddings[word]\n",
    "\n",
    "    # word_to_index is 1-based! the 0-th row, used for padding, stays at zero\n",
    "    embeddings[idx,] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Embedding Created ----------\n",
      "Number of words in corpus that do not appear in pretrained Fasttext:  1164\n",
      "size of the embedding: (10176, 300)\n"
     ]
    }
   ],
   "source": [
    "print('---------- Embedding Created ----------')\n",
    "print('Number of words in corpus that do not appear in '\n",
    "      'pretrained Fasttext: ', len(not_in_pretrained))\n",
    "print('size of the embedding: {}'.format(embeddings.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reducing Embeddings Dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components=REDUCED_DIM)\n",
    "embeddings = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generic Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel():\n",
    "    '''Generic workflow class.'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.verbose = kwargs.get('verbose', False)\n",
    "\n",
    "        self.nbCategories = kwargs['nbCategories']\n",
    "        self.paddingLength = PADDING\n",
    "        self.trainable = kwargs.get('trainable', False)\n",
    "\n",
    "    def train(self, x, y, epochs= 10, batch_size=32, validation_data=None, callback=False):\n",
    "        if callback == True:\n",
    "            filepath= '../models_checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_acc',\n",
    "                                         verbose=1, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "\n",
    "            return self.model.fit(x, y, shuffle='batch', epochs=epochs, verbose=1,\n",
    "                                  batch_size=batch_size, validation_data=validation_data,\n",
    "                                  callbacks=callbacks_list)\n",
    "        else:\n",
    "            return self.model.fit(x, y, shuffle='batch', epochs=epochs, verbose=1,\n",
    "                                  batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        return self.model.evaluate(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Model\n",
    "Here, we implement several models (CNN, RNN, etc) with different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import Input, Conv1D, Dense, Dropout, GlobalMaxPooling1D\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildCNN1D(self, embedding, drop_rate=0.3, nb_filters=128,\n",
    "                   filter_size=4, padding=PADDING):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = keras.Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = (Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding'))(my_input)\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "\n",
    "        conv1 = Conv1D(nb_filters, filter_size,\n",
    "                       activation='relu', name='conv1')(embedding_dropped)\n",
    "        pooled1 = GlobalMaxPooling1D(name='pool1')(conv2)\n",
    "        dropped1 = Dropout(drop_rate, name='drop1')(pooled1)\n",
    "        \n",
    "        prob = Dense(self.nbCategories, activation='softmax', name='softmax')(dropped1)\n",
    "        \n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import (Input, Conv2D, Dense, Dropout,\n",
    "                          MaxPooling2D, Flatten, Concatenate, Reshape)\n",
    "\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildCNN2D(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=[2,3,4],\n",
    "                   padding=PADDING):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = Input(shape=(self.paddingLength, ), name= 'input')\n",
    "\n",
    "        embedding = Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding')(my_input)\n",
    "        embedding = Reshape((padding, self.embedding.shape[1], 1))(embedding)\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "        \n",
    "        # one concatenates 3 filter sizes\n",
    "        conv0 = Conv2D(nb_filters, (filter_size[0], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv0', padding='valid')(embedding_dropped)\n",
    "        pooled0 = MaxPooling2D(pool_size=(padding - filter_size[0] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool0')(conv0)\n",
    "        \n",
    "        conv1 = Conv2D(nb_filters, (filter_size[1], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv1', padding='valid')(embedding_dropped)\n",
    "        pooled1 = MaxPooling2D(pool_size = (padding - filter_size[1] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool1')(conv1)\n",
    "        \n",
    "        conv2 = Conv2D(nb_filters, (filter_size[2], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv2', padding='valid')(embedding_dropped)\n",
    "        pooled2 = MaxPooling2D(pool_size = (padding - filter_size[2] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool2')(conv2)\n",
    "        \n",
    "        concatenated = Concatenate(axis=1)([pooled0, pooled1, pooled2])\n",
    "        flattened = keras.layers.Flatten()(concatenated)\n",
    "        dropped1 = Dropout(drop_rate, name='drop1')(flattened)  \n",
    "        prob = Dense(self.nbCategories, activation='softmax', name='dense2')(dropped1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistory(history):\n",
    "    plt.figure(figsize=(15,8))\n",
    "\n",
    "    plt.subplot(121)\n",
    "    plt.plot(history['acc'], label='Accuracy')\n",
    "    plt.plot(history['val_acc'], label='Validaction Accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy per Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(122)\n",
    "    plt.plot(history['loss'], label='Loss')\n",
    "    plt.plot(history['val_loss'], label='Validaction Loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss per Epoch')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input (InputLayer)              (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding (Embedding)           (None, 100, 100)     1017600     input[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape_4 (Reshape)             (None, 100, 100, 1)  0           embedding[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "drop0 (Dropout)                 (None, 100, 100, 1)  0           reshape_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 99, 1, 512)   102912      drop0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 98, 1, 512)   154112      drop0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 97, 1, 512)   205312      drop0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool0 (MaxPooling2D)            (None, 1, 1, 512)    0           conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool1 (MaxPooling2D)            (None, 1, 1, 512)    0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pool2 (MaxPooling2D)            (None, 1, 1, 512)    0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 3, 1, 512)    0           pool0[0][0]                      \n",
      "                                                                 pool1[0][0]                      \n",
      "                                                                 pool2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "flatten_4 (Flatten)             (None, 1536)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "drop1 (Dropout)                 (None, 1536)         0           flatten_4[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 51)           78387       drop1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 1,558,323\n",
      "Trainable params: 1,558,323\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "Total number of model parameters: 1558323\n"
     ]
    }
   ],
   "source": [
    "DROP_RATE = 0.4\n",
    "NB_FILTERS = 512\n",
    "FILTER_SIZE = 3\n",
    "\n",
    "model = CustomModel(verbose=False, nbCategories=NB_CATEGORIES, trainable=TRAINABLE)\n",
    "# model.buildCNN1D(embeddings, drop_rate=DROP_RATE, nb_filters=NB_FILTERS,\n",
    "#                  filter_size=FILTER_SIZE)\n",
    "model.buildCNN2D(embeddings, drop_rate=DROP_RATE, nb_filters=NB_FILTERS)\n",
    "model.model.summary()\n",
    "print('Total number of model parameters:', model.model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5786 samples, validate on 1447 samples\n",
      "Epoch 1/15\n",
      "5786/5786 [==============================] - 11s 2ms/step - loss: 2.7018 - acc: 0.3394 - val_loss: 2.0569 - val_acc: 0.5017\n",
      "Epoch 2/15\n",
      "1472/5786 [======>.......................] - ETA: 7s - loss: 1.9422 - acc: 0.5075"
     ]
    }
   ],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 15\n",
    "\n",
    "trainingHistory = model.train(xTrain, yTrain, epochs=EPOCHS, batch_size=BATCH_SIZE,\n",
    "                              validation_data=(xValid, yValid), callback = False)\n",
    "plotHistory(trainingHistory.history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606/1606 [==============================] - 1s 887us/step\n",
      "Accuracy: 68.49 %\n",
      "Loss: [1.3916359575718158, 0.68493150684931503]\n"
     ]
    }
   ],
   "source": [
    "model = keras.\n",
    "\n",
    "loss = model.evaluate(xValid, yValid)\n",
    "\n",
    "prediction = model.predict(xValid)\n",
    "predictionCategories = np.argmax(prediction, axis=1)\n",
    "yValidCategories = np.argmax(yValid, axis=1)\n",
    "accuracy = 100 * sum([predictionCategories[i] == yValidCategories[i]\n",
    "                      for i in range(len(yValidCategories))]) / len(yValidCategories)\n",
    "\n",
    "print('Accuracy: {:.2f} %\\nLoss: {}'.format(accuracy, str(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Accuracy Per Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPosition = np.arange(2*NB_CATEGORIES)\n",
    "\n",
    "c = collections.Counter(yValidCategories)\n",
    "od = collections.OrderedDict(sorted(c.items(), key=lambda x: x[0]))\n",
    "cp = collections.Counter(predictionCategories)\n",
    "odp = collections.OrderedDict(sorted(cp.items(), key=lambda x: x[0]))\n",
    "\n",
    "correctResults = predictionCategories[predictionCategories == yValidCategories]\n",
    "cc = collections.Counter(correctResults)\n",
    "odc = collections.OrderedDict(sorted(cc.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod = np.zeros(2*NB_CATEGORIES)\n",
    "for key in od:\n",
    "    pod[2*key] = od[key]\n",
    "\n",
    "podp = np.zeros(2*NB_CATEGORIES)\n",
    "for key in odp:\n",
    "    podp[2*key+1] = odp[key]\n",
    "\n",
    "podc = np.zeros(2*NB_CATEGORIES)\n",
    "for key in odc:\n",
    "    podc[2*key+1] = odc[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAHiCAYAAAC3Eh4FAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAGg4wQ8AAKDhBD8AAICG+/8BKnWgkjV32IMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f5da41f6f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "#plt.yscale('log')\n",
    "\n",
    "plt.bar(yPosition, pod, alpha=0.7, label='Appeared')\n",
    "plt.bar(yPosition, podp, alpha=0.5, label='Predicted')\n",
    "plt.bar(yPosition, podc, alpha=0.5, label='Correctly Predicted')\n",
    "\n",
    "plt.ylabel('Unique count')\n",
    "plt.title('Categories')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export Coefficients\n",
    "Predict results for the test data and output results in a `output_test.csv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "exportY = model.predict(xTest)\n",
    "exportY = np.argmax(exportY, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(os.path.join(dataDirPath, 'output_test.csv'), 'w+') as f:\n",
    "    f.write('ID;intention\\n')\n",
    "\n",
    "    for i, p in enumerate(exportY):\n",
    "        f.write('{};{}\\n'.format(str(i), str(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0, 32, 28, ..., 28, 14, 34])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exportY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
