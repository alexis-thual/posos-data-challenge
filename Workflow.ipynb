{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Notebook\n",
    "This notebook is intended to present models which are loaded from other files as well as the results they allow us to reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gensim\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CATEGORIES = 52\n",
    "PADDING = 100\n",
    "\n",
    "dataFolder = './challenge_data'\n",
    "xPath = os.path.join(dataFolder, 'input_train.csv')\n",
    "yPath = os.path.join(\n",
    "    dataFolder, 'challenge_output_data_training_file_predict_the_expected_answer.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, one defines the generic workflow which will be used after. In particular, the chronology we chose here is the following:\n",
    "* create model\n",
    "* preprocess signal (tokenize sentences, etc)\n",
    "* train model\n",
    "* predict on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel():\n",
    "    '''Generic workflow class.'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.verbose = kwargs.get('verbose', False)\n",
    "\n",
    "        self.nbCategories = kwargs['nbCategories']\n",
    "        self.paddingLength = PADDING\n",
    "        self.maxNumberWords = (1e5)\n",
    "        self.trainable = kwargs.get('trainable', False)\n",
    "\n",
    "        self.tokenizer = text.Tokenizer(\n",
    "            num_words=self.maxNumberWords,\n",
    "            filters=\"!\\\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n'´’™©®«»\",\n",
    "            split=\" \"\n",
    "        )\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        '''Turns sentences into padded word sequences.'''\n",
    "\n",
    "        self.tokenizer.fit_on_texts(x)\n",
    "        sequences = self.tokenizer.texts_to_sequences(x)\n",
    "        sequences = sequence.pad_sequences(sequences, self.paddingLength)\n",
    "\n",
    "        return sequences\n",
    "\n",
    "    def preprocessLabels(self, labels):\n",
    "        return to_categorical(labels, num_classes=self.nbCategories)\n",
    "\n",
    "    def train(self, x, y, epochs= 10, batch_size=32, validation_data=None,\n",
    "              callback=False):\n",
    "        if callback == True:\n",
    "            filepath= 'models_checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_acc',\n",
    "                                         verbose=1, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data,\n",
    "                           callbacks=callbacks_list)\n",
    "        else:\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        return self.model.evaluate(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize generic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Spelling corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctionsPath = os.path.join(dataFolder, 'corrections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def spellingCorrection(self, x, correct_dict={}, verbose=False):\n",
    "        corrected_x = []\n",
    "        for w in x.split():\n",
    "            if w in correct_dict.keys():\n",
    "                w_corrected = corrected_dict[w]\n",
    "                if verbose == True:\n",
    "                    print('Correction of ' + w + ' in ' + w_corrected)\n",
    "                w = w_corrected\n",
    "            corrected_x.append(w)\n",
    "        return ' '.join(corrected_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Differenciate medics from other words\n",
    "We here use a list of medication names to distinguish better between common words and specialized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste de médicaments regroupant les libéllés ATC et lesdénominations de spécialité, de taille: 8390\n",
      "Sample of medicament names:  ['a 313 200  pour cent', 'a 313 50 000 u.i', 'abacavir', 'abacavir/lamivudine', 'abacavir/lamivudine pharma', 'abacavir/lamivudine pharos', 'abamipharm', 'abboticine', 'abelcet', 'abstral']\n"
     ]
    }
   ],
   "source": [
    "MEDICAMENTS = []\n",
    "\n",
    "with open(os.path.join(dataFolder, 'medicList.txt')) as f:\n",
    "    for line in f:\n",
    "        MEDICAMENTS.append(line.lower().rstrip())\n",
    "\n",
    "print('Liste de médicaments regroupant les libéllés ATC et les'\n",
    "      'dénominations de spécialité, de taille: {}'.format(len(MEDICAMENTS)))\n",
    "print('Sample of medicament names: ', MEDICAMENTS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'ibuprofene' in MEDICAMENTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.medicaments = kwargs['medicaments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathematical Model\n",
    "Here, we implement several models (CNN, RNN, etc) with different shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import Input, Conv1D, Dense, Dropout, GlobalMaxPooling1D\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildCNN1D(self, embedding, drop_rate=0.3, nb_filters=128,\n",
    "                   filter_size=4, padding = PADDING):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = keras.Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = (Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding'))(my_input)\n",
    "#         embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "\n",
    "        conv1 = Conv1D(nb_filters, filter_size,\n",
    "                       activation='relu', name='conv1')(embedding)\n",
    "        pooled1 = GlobalMaxPooling1D(name='pool1')(conv1)\n",
    "        dropped1 = Dropout(drop_rate, name='drop1')(pooled1)\n",
    "        dense1 = Dense(self.nbCategories, activation = 'relu', name = 'dense1')(dropped1)\n",
    "        \n",
    "#         prob = Dense(self.nbCategories, activation='softmax', name='softmax')(dense1)\n",
    "        \n",
    "        self.model = Model(my_input, dense1)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import LSTM, Embedding, Dropout\n",
    "\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def buildLSTM(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=3):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = Embedding(input_length=self.paddingLength,\n",
    "                                input_dim=self.embedding.shape[0],\n",
    "                                output_dim=self.embedding.shape[1],\n",
    "                                weights=[self.embedding],\n",
    "                                trainable=self.trainable,\n",
    "                                name='embedding')(my_input)\n",
    "\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "        lstm1 = LSTM(100, name = 'lstm1', dropout= drop_rate,\n",
    "                     recurrent_dropout= drop_rate)(embedding_dropped)\n",
    "        dense1 = Dense(self.nbCategories, activation = 'relu', name = 'dense1')(lstm1)\n",
    "        prob = Dense(self.nbCategories, activation='softmax', name='softmax')(dense1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2D convnet for text classification: \n",
    "Inspired from : https://machinelearningmastery.com/sequence-classification-lstm-recurrent-neural-networks-python-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import MaxPooling1D, LSTM, Conv1D\n",
    "\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def buildLSTM_CNN(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=3):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = Embedding(input_length=self.paddingLength,\n",
    "                                input_dim=self.embedding.shape[0],\n",
    "                                output_dim=self.embedding.shape[1],\n",
    "                                weights=[self.embedding],\n",
    "                                trainable=self.trainable,\n",
    "                                name='embedding')(my_input)\n",
    "\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "        conv1 = Conv1D(nb_filters, filter_size, activation='relu',\n",
    "                       name='conv1', padding='same')(embedding_dropped)\n",
    "        pooled1 = MaxPooling1D(pool_size = 2, name = 'pool1')(conv1)\n",
    "        dropped1 = Dropout(drop_rate, name = 'drop1')(pooled1)\n",
    "        lstm1 = LSTM(100, name = 'lstm1',\n",
    "                     dropout= drop_rate, recurrent_dropout= drop_rate)(dropped1)\n",
    "        prob = Dense(self.nbCategories,\n",
    "                     activation='softmax', name='dense1')(lstm1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers.embeddings import Embedding\n",
    "from keras.models import Model\n",
    "from keras import Input\n",
    "from keras.layers import (Input, Conv2D, Dense, Dropout,\n",
    "                          MaxPooling2D, Flatten, Concatenate, Reshape)\n",
    "\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildCNN2D(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=[3, 5, 8],\n",
    "                   padding=PADDING):\n",
    "        if np.isscalar(filter_size):\n",
    "            filter_size = [3, 5, 8]\n",
    "            print(\"WARNING: You have to enter a list for the different\\\n",
    "            filter sizes, we modified directly to: {}\".format(filter_size))\n",
    "        \n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = Input(shape=(self.paddingLength, ), name= 'input')\n",
    "\n",
    "        embedding = Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding')(my_input)\n",
    "        embedding = Reshape((padding, self.embedding.shape[1], 1))(embedding)\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop0')(embedding)\n",
    "        \n",
    "        # we concatenate 3 filter sizes\n",
    "        conv0 = Conv2D(nb_filters, (filter_size[0], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv0', padding='valid')(embedding_dropped)\n",
    "        pooled0 = MaxPooling2D(pool_size=(padding - filter_size[0] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool0')(conv0)\n",
    "        \n",
    "        conv1 = Conv2D(nb_filters, (filter_size[1], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv1', padding='valid')(embedding_dropped)\n",
    "        pooled1 = MaxPooling2D(pool_size = (padding - filter_size[1] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool1')(conv1)\n",
    "        \n",
    "        conv2 = Conv2D(nb_filters, (filter_size[2], self.embedding.shape[1]),\n",
    "                       activation='relu', name='conv2', padding='valid')(embedding_dropped)\n",
    "        pooled2 = MaxPooling2D(pool_size = (padding - filter_size[2] + 1, 1),\n",
    "                               strides=(1, 1), padding='valid', name='pool2')(conv2)\n",
    "        \n",
    "        concatenated = Concatenate(axis = 1)([pooled0, pooled1, pooled2])\n",
    "        flattened = keras.layers.Flatten()(concatenated)\n",
    "        dropped1 = Dropout(drop_rate, name='drop1')(flattened)  \n",
    "        prob = Dense(self.nbCategories, activation='softmax', name='dense2')(dropped1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy']\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model variables\n",
    "TRAINABLE = False # Training the embedding can lead to overfitting\n",
    "PRE_TRAINED_DIM = 300 # Size of the pretrained embedding used here\n",
    "REDUCED_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instance creation\n",
    "model = CustomModel(nbCategories=NB_CATEGORIES, trainable=TRAINABLE, medicaments=MEDICAMENTS)\n",
    "\n",
    "# Loading, parsing and spliting training and testing data\n",
    "x = pd.read_csv(xPath, delimiter=';', usecols=[1]).values.ravel()\n",
    "y = pd.read_csv(yPath, delimiter=';', usecols=[1]).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling mistakes\n",
    "corrected_dict = {}\n",
    "for key, val in csv.reader(open(correctionsPath)):\n",
    "    corrected_dict[key] = val\n",
    "for i, s in enumerate(x):\n",
    "    x[i] = model.spellingCorrection(s, corrected_dict, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  9341\n"
     ]
    }
   ],
   "source": [
    "# Print some info about our vocabulary\n",
    "model.preprocess(x)\n",
    "x_vocab  = list(model.tokenizer.word_index.keys())\n",
    "print('Vocabulary size: ', len(x_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unidecode import unidecode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Embedding Created ----------\n",
      "Number of words in corpus that do not appear in pretrained Fasttext:  1340\n"
     ]
    }
   ],
   "source": [
    "# Loading and using pretrained embedding (fasttext or EMEA)\n",
    "embeddingPath = '../wiki.fr.vec'\n",
    "# embeddingPath = '../word_embeddings/retrained_fr.vec'\n",
    "\n",
    "pre_trained_wv = gensim.models.KeyedVectors.load_word2vec_format(embeddingPath,\n",
    "                                                                 binary=False)\n",
    "\n",
    "# We use an embedding size of len(x_vocab) + 1 because the 0 is used for the padding\n",
    "embeddings = np.zeros((len(x_vocab) + 1 , PRE_TRAINED_DIM))\n",
    "not_in_pretrained = []\n",
    "detected_medic = []\n",
    "\n",
    "for word, idx in model.tokenizer.word_index.items():\n",
    "    if word not in pre_trained_wv.vocab:\n",
    "        unaccented = unidecode(word)\n",
    "        if word in model.medicaments:\n",
    "            vec = pre_trained_wv['médicament']\n",
    "            detected_medic.append(word)\n",
    "        else:\n",
    "            vec = np.zeros(PRE_TRAINED_DIM)\n",
    "            not_in_pretrained.append(word)\n",
    "    else:\n",
    "        vec = pre_trained_wv[word]\n",
    "\n",
    "    # word_to_index is 1-based! the 0-th row, used for padding, stays at zero\n",
    "    embeddings[idx,] = vec\n",
    "\n",
    "print('---------- Embedding Created ----------')\n",
    "print('Number of words in corpus that do not appear in '\n",
    "      'pretrained Fasttext: ', len(not_in_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "363"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(detected_medic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "# reduce embedding dimension\n",
    "pca = PCA(n_components=REDUCED_DIM)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the embedding for convenience\n",
    "#np.save('challenge_data/fasttext_voc_not_corrected.npy', embeddings)\n",
    "#np.save('challenge_data/fasttext_emb.npy', embeddings)\n",
    "# np.save('challenge_data/fasttext_retrained.npy', embeddings)\n",
    "#embeddings = np.load('challenge_data/fasttext_emb.npy')\n",
    "#embeddings = np.load('challenge_data/fasttext_voc_not_corrected.npy')\n",
    "# embeddings = np.load('challenge_data/fasttext_retrained.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 100, 100)          934200    \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 98, 1024)          308224    \n",
      "_________________________________________________________________\n",
      "pool1 (GlobalMaxPooling1D)   (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "drop1 (Dropout)              (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense1 (Dense)               (None, 52)                53300     \n",
      "=================================================================\n",
      "Total params: 1,295,724\n",
      "Trainable params: 361,524\n",
      "Non-trainable params: 934,200\n",
      "_________________________________________________________________\n",
      "Total number of model parameters: 1295724\n"
     ]
    }
   ],
   "source": [
    "# Model parameters among (drop_rate=0.3, nb_filters=32, filter_size=3)\n",
    "DROP_RATE = 0.3\n",
    "NB_FILTERS = 1024\n",
    "FILTER_SIZE = 3\n",
    "#FILTERS_SIZES = []\n",
    "# Build our model\n",
    "model.buildCNN1D(reduced_embeddings, drop_rate=DROP_RATE, nb_filters=NB_FILTERS,\n",
    "                    filter_size=FILTER_SIZE)\n",
    "model.model.summary()\n",
    "\n",
    "print('Total number of model parameters:', model.model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data and labels before training\n",
    "y = model.preprocessLabels(y)\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xTrain = model.preprocess(xTrain)\n",
    "xTest = model.preprocess(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 17s 3ms/step - loss: 8.4783 - acc: 0.2199 - val_loss: 8.1252 - val_acc: 0.2360\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 20s 3ms/step - loss: 8.2376 - acc: 0.2414 - val_loss: 8.0307 - val_acc: 0.2590\n",
      "Epoch 3/10\n",
      "6422/6422 [==============================] - 20s 3ms/step - loss: 8.1263 - acc: 0.2638 - val_loss: 8.2292 - val_acc: 0.2821\n",
      "Epoch 4/10\n",
      "6422/6422 [==============================] - 24s 4ms/step - loss: 8.0534 - acc: 0.2801 - val_loss: 7.9477 - val_acc: 0.2933\n",
      "Epoch 5/10\n",
      "6422/6422 [==============================] - 22s 3ms/step - loss: 8.0854 - acc: 0.2182 - val_loss: 8.0427 - val_acc: 0.2790\n",
      "Epoch 6/10\n",
      "6422/6422 [==============================] - 22s 3ms/step - loss: 8.0199 - acc: 0.2923 - val_loss: 8.6888 - val_acc: 0.2902\n",
      "Epoch 7/10\n",
      "6422/6422 [==============================] - 21s 3ms/step - loss: 7.9814 - acc: 0.3135 - val_loss: 8.4252 - val_acc: 0.2883\n",
      "Epoch 8/10\n",
      "6422/6422 [==============================] - 21s 3ms/step - loss: 7.9413 - acc: 0.3284 - val_loss: 8.3789 - val_acc: 0.2864\n",
      "Epoch 9/10\n",
      "6422/6422 [==============================] - 21s 3ms/step - loss: 7.9051 - acc: 0.3555 - val_loss: 9.0088 - val_acc: 0.2391\n",
      "Epoch 10/10\n",
      "6422/6422 [==============================] - 21s 3ms/step - loss: 7.8820 - acc: 0.3373 - val_loss: 8.8934 - val_acc: 0.3020\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10\n",
    "\n",
    "model.train(xTrain, yTrain, epochs=EPOCHS, batch_size= BATCH_SIZE,\n",
    "            validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606/1606 [==============================] - 1s 539us/step\n",
      "Accuracy: 30.20 %\n",
      "Loss: [8.893423225336324, 0.30199252801992527]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(xTest, yTest)\n",
    "\n",
    "prediction = model.predict(xTest)\n",
    "predictionCategories = np.argmax(prediction, axis=1)\n",
    "yTestCategories = np.argmax(yTest, axis=1)\n",
    "accuracy = 100 * sum([predictionCategories[i] == yTestCategories[i]\n",
    "                      for i in range(len(yTestCategories))]) / len(yTestCategories)\n",
    "\n",
    "print('Accuracy: {:.2f} %\\nLoss: {}'.format(accuracy, str(loss)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot accuracy per category."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "yPosition = np.arange(2*NB_CATEGORIES)\n",
    "\n",
    "c = collections.Counter(yTestCategories)\n",
    "od = collections.OrderedDict(sorted(c.items(), key=lambda x: x[0]))\n",
    "cp = collections.Counter(predictionCategories)\n",
    "odp = collections.OrderedDict(sorted(cp.items(), key=lambda x: x[0]))\n",
    "\n",
    "correctResults = predictionCategories[predictionCategories == yTestCategories]\n",
    "cc = collections.Counter(correctResults)\n",
    "odc = collections.OrderedDict(sorted(cc.items(), key=lambda x: x[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "pod = np.zeros(2*NB_CATEGORIES)\n",
    "for key in od:\n",
    "    pod[2*key] = od[key]\n",
    "\n",
    "podp = np.zeros(2*NB_CATEGORIES)\n",
    "for key in odp:\n",
    "    podp[2*key+1] = odp[key]\n",
    "\n",
    "podc = np.zeros(2*NB_CATEGORIES)\n",
    "for key in odc:\n",
    "    podc[2*key+1] = odc[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4sAAAHkCAYAAACXLrrFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzs3XecVNX9//HXzBZA+oJjBEFQ0MRkEh2KEjGJJQaNvaapaWqMfE1MftG0rzEaSzSaGEtsMSbxa4wRsWCMiRWxAgM4YqFIURAvbWnC1vn9McNm4c4uA8wyw+7r+Xjsg51z7tz72dmT4Jtz7rmRdDqNJEmSJEnNRYtdgCRJkiSp9BgWJUmSJEkhhkVJkiRJUohhUZIkSZIUYliUJEmSJIUYFiVJkiRJIYZFSZLagWQquDuZCp4sdh2SpPajvNgFSJK0oyRTQR/gYuB4YE9gNfAWcCdwbyIeq8/jHPXAtxPx2N1tWOq2+B7+I7AkqYAMi5KkDiGZCgYAk4B64BJgGlAHfBr4f8BrwPSiFbiNkqmgIhGP1SXisVXFrkWS1L5E0ul0sWuQJKnNJVPBo8AIYN/Ng1UyFVQAlWSC48+ATwJlZMLjjxLx2KvZ4+aTmZFskojHItm+YcBV2XOsB54HLkzEYwuaXef7ZIJpVbb/HuAvwIBEPPZe9pijgcuBTwCrgAeyNazL9t8N7AE8DPwQGAh0Bf4A7JGIx45odr0vAT8GPgosAR4E/rfZuUYDv87+vADvABcl4rEn8v1cJUntl8tVJEntXjIVVAFHAzflmoHLzsytA7oBtwCjyIS+2cC/sstXIRM2G4DvA7tnv0imgv2A54CXgOHAYdnj/pNMBZ2zx5wE/Aa4FvgU8DcyQa15nZ8EHgEmZo85CzgGuHWzkkdmr3F89rjaHD/z18kEyOuA/YAzgSM2niuZCsqz13oFSGS/LgU+zPkhSpI6HJehSpI6giFk/oH0jdYOSsRj45u/TqaCc4CTgTHA/yXisaXJVACwKhGPLWl26EXAhEQ89otm7/0asDL73ofIzAL+LRGP3ZA9ZHYyFXyUzD2UG/0ISCbisQuzr99KpoL/AcYnU8HPm81SNgJnJOKxtc2ut/mPcynwk0Q89tfs63eSqWAs8FwyFVyQbesNPJKIx2ZvrKmVj0eS1MEYFiVJHUEkn4OSqWAwcBmZmcUYmYC5C5stPc1hBDAkmQrWbtbeGRia/X4/4N7N+l/a7PXHgac3a3uOTP37ARvD4pvNg2KOn2PXbM3XJ1PBb5p1bfwchiTiscnJVHAn8EQyFTydvc74RDz2dkvnlSR1LC5DlSR1BLPJzMbtt4XjJpC5B/B84CBgfyAgcz9ja6LAX7PHN//ah8xOqxsVaqOAdXnUA5kdUpvX8yky4TUFkIjHzgaGAf8BPgu8nkwF5xaoRknSTs6ZRUlSu5eIx1YkU8HjwNhkKrixhQ1uYmTC5NEbN3hJpoI9su3N1ZLZ/Ka5KWQ2iZmbiMdaCoRvkJmxvKVZ20GbHTMT+MxmbZ8lEzJntnDekEQ89kEyFbxLZjOfO7Zw7OvA62RmIW8FzgFuy/dakqT2y7AoSeoovgu8AExNpoJLyOx0WksmsP0I+AawFDg7mQrmAn2Aa8jsbNrcPODQbPisTcRjy4ArgVeBe5Kp4IbseQYBJwA3JOKxd8hsNPP3ZCp4FXiczAY6Z2bPuTFgXgskk6ngt2QC2yDgRjL3Sy7cyp/3Z8Afk6lgJZmdU+uAjwFHJeKxc5OpYAhwNvAo8C7QDzgESG7ldSRJ7ZTLUCVJHUI2bCXIbDZzKZlQ9CKZwHQtmecsngrsnf3+buB3wPubneqHZJZuzicTCknEY2+SCX/dgCfIzCLeAXQBqrPHPEhmI5wfk1kG+lXgl9lzbsge8xpwHJnZxRlklrY+BnxnG37evwKnkdlN9VVgcvbnXpQ9ZB2ZJan3AbOAcdnPY+zWXkuS1D75nEVJkookO8N5QSIe61vsWiRJ2pzLUCVJ2gGy90X+EPgnmVm9Q8ksf725mHVJktQSw6IkSTtGGvgcmcDYncy9j1eSWQIrSVLJcRmqJEmSJCmkw84sXnPHExFgD2B1sWuRJEmSpCLpAbx30dlfCM0idtiwSCYobu025JIkSZLU3gwk8xilTXTksLga4PGH7qG+vq7YteQUiUTot+cQFi+Yg8uFta0cRyoUx5IKxbGkQnAcqVA68lgqL6/gqBO+Bi2stuzIYRGA+vo66utqi11GTpFIlIaGBurr6kinG4tdjnZSjiMVimNJheJYUiE4jlQojqWWRYtdgCRJkiSp9BgWJUmSJEkhhkVJkiRJUkiHv2dRkiRJKpRoNEqnyopil6GtEIlkfmddOndqd/cs1tXVU9/QsM3vNyxKkiRJBdCnqheNjY1s2FBT7FK0FdLpRoLFC9tdUATo2rULnSor2VBTy+o1a7f6/YZFSZIkaTtFo1EaGxtZWZ3zCQQqcRWNEepq21/IX5/9h4s+Vb2IRCJb/WgQ71mUJEmStlOnygpnFFWyPly/gc6dKrf6fYZFSZIkSWrPtnJGcSPDoiRJkiQpxLAoSZIkSQpxgxtJkiSpjTTsdWKbX6PsnfFtfo2dyWWXXMH4h8cxbUay2KXs9JxZlCRJkjqY00/9MjffcCuDBw0udikqYYZFSZIkqQOpqKhgeGIEa9et5dOjRhe7nBZFo0aVYnMZqiRJktSBHLB/gnQ6zbgH/8Hpp36ZB8bdT01tDUOH7MN553yX8Q8/yJgjj6asvIxXJ7/MQ4+Mp7GxcYv9AP379efkE0+lf/89WL9+Pc9OfIZnn3sagN69e/PVL53BgD0GEo1GWLBwAX9/4D6WLg0AOOMrZwFQXlHOxz/2CZ548l/858knGDpkH44/9gR2i+3G6tWr+ee/HmPqtClNP8/RY47hkIMPAeCpZ57akR9lu2dYlCRJkjqQgw8azdRpU0hOm8opJ53GsMRwXnz5BQAqKirZa/Be/PKKS+jRvQdjz7uAVatW8dQzT26xv3v37lww9kIeePB+pian0LdPX84/7wJWVVczbUaSSCTKM889zazZbxONRDnt1C/x9a99g2t/++um2oYlhnPHXbdx91/uory8nN1378c53/oOd/35Tt56+00GDBjI2O9cwNLlS1m4cAEHjRzFwaNG8/ubf8ey5cs46YRT6NWrV1E+1/bIuV1JkiSpg4jtGmPIkKG88upL1DfUM3XaFEYddHBTfzQa5aFHxlNbW8uy5ct48pn/MHL4gXn1HzjiIObNf4fJU16lsbGRYGnA85MmMnJEpn/FiuXMfON16urqqKmt4bHHJzBo0GAqK//7sPi3Zr3JzDdeJ51OU1dXxyEHf4bJU17lzbfeIJ1Os3DhAqZOm9J0zRHDRzJx0rO8v+R96urqeOjhB3fEx9hhOLMoSZIkdRCfHjWaJUveZ/6C+QC8/MpLXPTDz7L7R3YHoKGhgVWrVzUdv2L5cno2m6lrrb+qqg8f3fdjXHvV9U390WiUJR8sAaBr166ccuKpDB2yD527dIHsc+K7de3GitoVAKxcuXKTevtU9WGfofsyYvjIpraysigz35gJQK+evVixYkVTX01tDevWrd22D0chhkVJkiSpA4hGoxw44kA6d+7CVZf/epO+UQcdTOr11ygrK6Nnj55NgbCqTx9WVVc3Hdda/8qVK3j99RR3/un2nNc//pgT2WWXrvz6uqtYs2YNVVV9uPwXV0Ak0nRMujG9yXtWrlzBxEnPMf7hcTnPWb2qmqqqqqbXnSo70bVrt3w/Em2BYVGSJG1i6LDc/yo/e6r/ASbtzOKf+CRddtmFq6+5kg8/XNfUPmL4gXz+iCN5482ZNDY2ctyxJ3Df/ffSo0dPDj/087zw4vNNx7bW/+rkVzj80CMYlhjO9BnTSKfT7BbbjS5dduGdeXPp3LkzNTU1fPjhh3TpsgvHffH4Ldb8/AsT+Z/zv8+bb73BrNlvE4lE6N+vPw0NDSxavIgpUyfzxaOOYfpr01m+fBnHH9v2z7XsSAyLkiRJUhspe2d8sUtocvCo0UydOoUlH7y/SfukFyYy5sgx7NJlF+rqapk/fx6X/vxyysrLmDzlVZ5+9r87jLbWv2r1Km685QZOOO4kTj35dMqiUYIg4PF//xOACY8/yplfPYtrr7qOVatX868n/rnJ8tJcFi1exJ133c6xXzyOb571bdKkWbx4MY9MyHyuL7/6ElVVffj+2AshEuGpp5+kutlMqLaPYVGSJEnqAG657aac7TW1NfzoJz9k6JB9gMxs3vMvTGzxPK31L1q8iJtvvTFnXxB8wG9+e80mba9Mfrnp+7/e++ec75szdza//f11OfvS6TSPPf4ojz3+aFPbk0//u8XatXXcDVWSJEmSFGJYlCRJkiSFGBYlSZIkMXvOLH5w0fe3uV/tj2FRkiRJkhRiWJQkSZIkhRgWJUmSJEkhhkVJkiRJUohhUZIkSZIUUl7sAiRJkqT2auiwtW1+jdlTu7X5NfJ19JhjGDhwILfefgsAP//xJTzy2MO8lpqxQ65/2SVXMP7hcUybkdwh12vvDIuSJElSB/G9sT9g8ODBNDY00NDQyAfBEh597GHenvV2m1zvV1dfltdxB40cxeGHHcEVV1/eJnVo27gMVZIkSepAHp3wCD+46Pv85OcXMW/+PM751nl07tx5k2OiUWOCnFmUJEmSOqT6hnpefPkFDvvc4Rw8ajRfPOoYxo1/gDFHHkVNTQ2/uvoyunXtxkknnMK++36UaCTCjNQMHnzoAWprawHYa/DenH7ql9m1b19mz5nNsuXLNrnG5stCP7rvxzj26OOIxXajrq6OZyc+zRtvvsGXTvsKZWVlXH/N7wC4+torCZYGDB2yD8cfewK7xXZj9erV/PNfjzF12pSm8x895hgOOfgQAJ565qkd8bF1KIZFSZIkqQOqqKjg0wcdzPr16wmWBlRUVLLnwEFcftUvSafTAJx79nksfHchl/3qF0TLonzjzG9xwrEncf+4++jSpQvnnfNdHn3sESa9+Dz7DN2Xc771HWbNyb2kdY/+Azj32+fx53v+xGupGVRWVvKR3XbnvUXvct/994aWoe6+ez/O+dZ3uOvPd/LW228yYMBAxn7nApYuX8rChQs4aOQoDh41mt/f/DuWLV/GSSecQq9evXbIZ9dROL8sSZIkdSDHHH0s1151PZf94gr26L8Hf7j9ZjZs2EA0GuXhCeOpra2lrq6OgQP35CO77c4DD95PTW0N69ev57HHJzByxIEAfOLjcdasXcvESc/R2NjIW2+/SWrmay1ed/SnR5OcNpXpM6bR2NjIhg0bmL9gXovHH3LwZ5g85VXefOsN0uk0CxcuYOq0KYwcnrn+iOEjmTjpWd5f8j51dXU89PCDhf2g5MyiJEmS1JFM+OejPPXMfzZpGzpkH2pra1m3bl1TW5+qPnTu3JlrrryuqS0SiVBeXk6XLl3o1bMXK1au2OQ8K1YsZ/fd++W8blVVH96ZNzfvOvtU9WGfofsyYvjIpraysigz35gJkLn+iv9ev6a2hnXr2n732Y7EsChJkiSJdLpxk9crV65g3Yfr+PHPfpTz+OpV1VT1rtqkraqqT4vnX7FiObv2jeXsa9zs2huvP3HSc4x/eFzL16/67/U7VXaia9fSeYxIe+AyVEmSJEkhCxYuYOnSpZxw3ElNu6X26tmLT3w8DsDrM1+ne7fuHHLwZ4hGo+y7z77Es325vPDSJBIHDONTn9yfaDRK586dGbTnYADWrFlDj+49qaioaDr++RcmcuDIg/jovh8jGo1SVlbGwAED6d+vPwBTpk7mkIM/w267fYTy8nKOP/bEtvooOixnFiVJkqQ2MnvqzjvTlU6nue2OWzju2BP4+Y8voXOXLqyqrublyS/z+swU69d/yK133MLpp36JE48/idlzZvPSKy/Rp0/u2cV333uXO+66jWOOPpYzvnoWNTU1PPvc08xfMI+3Z73F3HfmcMUvryYSiXDN9VezaPEi7rzrdo794nF886xvkybN4sWLeWTCeABefvUlqqr68P2xF0IkwlNPP0l1dfWO/IjavcjGnY46mmvueKInUP3oA3+ivq622OXkFIlE6T94HxbNmxVaFiDly3GkQnEsdRxDh+W+56dQ/9HrWFIhlNo46tK5EwDrN9QUuRJti4rKztTVbih2GW2mpfFZXlHJsad8A6DXRWd/YdXm73MZqiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkkPJiFyBJkiS1V0dWtv01/l3b9tcoBd8b+wNen5niqWf+U+xScjpo5CgOP+wIrrj6cgC+e+5Y3nhzJs9OfGaHXL8tPh/DoiRJktSBDB60F0d94WgGDxpMJBJlZfUKpian8tQz/6Gurq7Y5QFw2SVXMP7hcUybkSzI+c74ylkMHzaChoZ6GtNpli9fzhP/fpzk9KkFOX8ut9x2U17HDR2yD+ed811+cNH326yWbWVYlCRJkjqIj+/3Cc7+5rn856knuOdvf2H16tX06dOXIw77PLFdYyxavGirzheNRmlsbNykLRKJAJBOpwtWdyG88OIk7h93H9FolEM/exhfP/ObvLf4PYLgg02Oy/UzdVSGRUmSJKmDOO3k03ll8ss89viEprbly5fx93/8rel13z59Oe2ULzFoz8Gs37Cel15+gSf+8y/S6XTTLNi48Q8w5sijqKmp4VdXX8bNN9zKP8b9nU+POphYbDcuufRnrF23ljFHHsXI4Qeyyy5dWbBwPvfdfy/LVywHoHOnzhx3zAnEPxGnyy67EAQfcPsfb+PkE06hd+/enPm1r3PGV89k2vRp/PXeP2/yc1z8/37K85Oe48WXX2hq+/Y3ziFYGvDIhIda/QwaGxuZ9MLznHTCKfTbvR/19fVc/osruOdvf+HII8bQo3sPfnjx96msrOT4Y07gk5/cn4qKCmbNepu/P/A31q1bB8Buu32Er37pDPr368+ixe/x9qy3NrnO5stCB+wxkBOPP4k9+g+gMd3I1OQU/vn4BL577lgqKyu5/prfAXDbnbfy9qy36N+vPyefeCr9++/B+vXreXbiMzz73NNN5x998CF84YgxdOrUmZdffYlsRi8ow6IkSZLUAcR2jdG3765Mve+eFo+JRqOcd+5YZr7xOrf/8Vaqqvpw/rlj2bBhQ9O9dxUVlew5cBCXX/XLTWYPhw8bwS233sSatWtobGzkuGOOZ69Be/O7G69n9ZrVjDnyaM759nlcfe0VpNNpzvjqWVRWVvKb317D6jWr6d9vD+rqavnj3XdscRnqSy+/wEEHjmoKi1136conPh7nil9fvsXPIRqNMvrgz9DQ0LDJTOonP/Eprr3+6qaluF/98hlEI1GuvuYKautqOfXk0znjq2dx6+23EI1G+c7Z32X6jCS/v+m37L57P7577vmsXbc25zV79uzF9/7nQh5+9CFuue0mIpEIAwfsyboP13HLbTeFlqF2796dC8ZeyAMP3s/U5BT69unL+eddwKrqaqbNSDJk76GceNzJ3HzrjcxfMI/PH34kew3em9TrqS3+/FvD3VAlSZKkDqBbt+4ArFpV3eIxg/YcTO9evXjk0Yeor68nCD7gyWee5MCRo5qOiUajPDxhPLW1tZvc4/jU009SvaqahoYG0uk0nxn9OcY99A+qV1XT2NjI4088xq59+9K/3x50796d/T91AH+7/15WrV5FOp3mvUXvNs3abcnkqa8yYI+B7LprDIARw0eyYOF8li4NWnzPpz99MNdedT1XXX4Nif0T3Pmn2zc5/vEnHuPDDz+krq6Obl27kdh/GH//x99Y9+E66urqeGTCw8Q//km6dNmFwYMG06N7Dyb881HqG+p5972FvPzqSy1ee+Twkbz77rs8P+k56uvrqaurY+47c1o8/sARBzFv/jtMnvIqjY2NBEsDnp80kZEjDsycb8SBTElO5p15c2lsbOTfTz7BmrVr8vrstoYzi5IkSVIHsHHWq2fPXnyw2X16G/Xq1YtVq1dT31Df1LZ82VJ69+rV9Lq2tjZnqFuxckXT9926dqNz585ccP6Fm8w+RiJRevfuTVlZGQ0NDazILkndWuvXr2f6jCSjDhzFIxMe5qADR21x19EXX3yB+8fd12L/ipUrm76v6tOHaDTKL35+2SbH1NXVUdW7Nz179mL1mtU0NDQ09S1v5WepqurD0mUtB9lcx390349x7VXXN7VFo1GWfLAEgF49ezH3nblNfel0mpXNPv9CMSxKkiRJHUAQfMCyZUsZdsAwZs1+O+cx1dXV9OzRg/Ky8qbAWNWnDyur/zsbmU7n3vylefvadWupqanhuhuu5f33F4eO7d69O2VlZVRV9ckZGFu6RnMvvPQCXz/zm0ybnmTXvjGS07ZvZ9Pm11y5cgWNjY3876U/ZUPNhtCxnTt3pkf3Hk2hF6BPVZ8Wz71ixXL2+9gntnjd5td//fUUd/7p9pzvqV5VTVVVVdPrSCRC715VOY/dHjt0GWoyFZyWTAWTkqlgbTIVzN+srzyZCm5IpoIVyVRQnUwFf0ymgs6F6pckSZI6uvvH/Z0DR47i6DFfpHv3zLLUqt5VnHrSafTr15/5C+ZRvWoVxx5zPOXl5cR2jXHEYUfyyuSXt/paEyc9x0nHn0xV70yI6dKlCwd8KkFZWRlr1qxhxmvTOf2UL9GjRw8ikQh79B9A1126ArB6zRr69u3b6vnnzJ1NbW0tX/3yGSSnT6W2tnAPnFyzZg3TZ0zj9FO/1LR8t1u37hzwqQQA8+bPY82a1XzxqGMoKytjj/4DOHDEqBbPN3nKqwwcMJDRBx9CeVk5FRUV7L3XECDzs1ZUVNKje4+m41+d/ApD9h7CsMRwysrKiEaj7P6R3dlr8N4ATJk6mWGJ4QweNJhoNMoRhx/Z9PsspB09s7gSuAnYDbhws76fAocCcaAWeAS4BrigQP2SJEnSDvXvwuWXgpj5xuvccNNvOeoLR3PoZw8nEomwsnoFU6ZOYenSgMbGRv5w+82cdvLpXHnZr9mwYQMvv/oiz23Dg+UfmfAQnz/8SMZ+93v07NGTD9d/yJw5s5iRmg7AX/7vbk447iQu+uFP6Ny5Mx8sWcIdd90GwBP/eZxTTz6dI48Yw/TXpvF/f/trzmu89PILnHDcSdz/wN+3+TNpyT33/oWjjzqGH/3gYrp17caatWtIvf4a02YkaWxs5LY7/8BXvnQG1151KO8teo8XXnqe/T91QM5zVa+q5vc3/46Tjj+Z4485kYaGeqYkpzD3nTkEwQe8+NIkfvbjS4hGo9z5p9t4e9bb3HjLDZxw3EmcevLplEWjBEHA4//+JwCzZr/NI48+xLe+fjadOnXipVde4p15c3Nee3tEivH8k2QqOAH4XSIeG9SsbSFwUSIeuy/7+gvAP4DeiXisYXv7N6/hmjue6AlUTxh3N/Ul8vDRzUUiUfoNGsLi+XPymoqXcnEcqVAcSx3H3gfk3mBi7rSuBTm/Y0mFUGrjqEvnTqTTjazfUFPsUjqUxP7D+OLRx3L5lZdu13kqKjtTVxtebtpedOnciUgkGhqf5RUVHHPy1wF6XXT2F1Zt/r6SuGcxmQp6AQOA6c2bge7AoGQqWL49/UCLMbvfnkM2uTG1FPUbNKTYJagdcBypUBxL7d+GFjZK7D+4sNdxLKkQSmUcdaqsIFi8kIrGNnjYnXKqqKjg0EMP58WXXqSicvvvPivEOUpVeWUnYv0GUlO76SRZWVlZ6+9ry6K2wsYFts3/eqpu1le7nf0tWrxgjjOLatccRyoUx1LH4cyidgalNo42zizW1TqzuCMMHzaCr5z+NebMnc1zE5/eZPfWbdHeZxbLo2neXzAn58xiYvjolt/X1oXlaeNDQXoCS7Lf92rWt739LUqn0yXxfzCtSacbS75GlT7HkQrFsdT+RSK5V9wU+vfuWFIhlMo4KoUaOpIpUyczZerkYpexU8n1v5Ut3ZK4Q3dDbUkiHqsG3gX2b9Z8AJmgN397+9uuckmSJEkqcZFtWx69Q2cWk6mgDKjIfkWyj7ZIJ+KxGuBO4CfJVPA8UAdcCtzdbHOa7e2XJEmS2kRNbR09e3RzgxuVpF26dGbFytD+NVu0o5ehngH8qdnr9cACMpvQXAn0BWaSmfF8ALi42bHb2y9JkiS1icbGRqLRKL179WBDTS0U4YkD2nbllZ0oj7az31kkQmVFOZWVFdTU1G1xyWkuOzQsJuKxu4G7W+irJ/NMxJzPRdzefkmSJKktLV9RTTQapVNlRbFL0VaIRKLE+g3k/QWlsVlSwaTTrFu3nlWr127zKUplgxtJkiRpp9fY6LMWdzaRSJSa2jrWb6hpX2GxAEpigxtJkiRJUmkxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKaS82AU0l0wFuwM3AZ8FIsDzwNhEPPZeMhWUA9dQe419AAAeIUlEQVQBZ5AJueOA8xPx2Ibse1vtlyRJkiTlr9RmFm8BKoHBwABgHXBXtu+nwKFAHBgK7Adc0+y9W+qXJEmSJOWppGYWgb2B3yTisTUAyVRwL/DHbN+3gYsS8diibN+lwD+SqeDCRDzWkEd/TpFIhEik1DJzxsa6SrU+7RwcRyoUx1LHkU6X5Wwv1O/esaRCcBypUDryWIpEIq32l1pYvB44JZkKHgEayCwpfTSZCnqRmWmc3uzYJNAdGJRMBctb6wfmtnTBfnsOoaGhxSxZEvoNGlLsEtQOOI5UKI6l9m9Dde72/oMLex3HkgrBcaRC6Yhjqaws9z8OblRqYXES8E1gBZAGXgOOJBP6AJr/9bXx++5A7Rb6W7R4wRzq6+q2o+S2E4lE6TdoCIvnzyGdbix2OdpJOY5UKI6ljmPvA9blbJ87rWtBzu9YUiE4jlQoHXkslVdUkBg+uuX+HVhLq5KpIAo8CTwIHE1mZvEi4Fngc9nDegJLst/3yv65JvvVWn+L0ul0yQ+KdLqx5GtU6XMcqVAcS+1fJJJ7xU2hf++OJRWC40iF0hHHUjqdbrW/lBbmVgF7Ar9PxGNrE/HYejLLUvcD+gDvAvs3O/4AMkFwfiIeq26tv+1LlyRJkqT2pWRmFhPx2LJkKpgDnJ9MBZeQmVn8HrCSTOC7E/hJMhU8D9QBlwJ3N9u8Zkv9kiRJkqQ8ldLMIsDxZB598R7wAfAF4JjssxKvBCYCM4E5wJvAxc3eu6V+SZIkSVKeSmZmESARj70BjGmhrx64IPu11f2SJEmSpPyV2syiJEmSJKkEGBYlSZIkSSGGRUmSJElSiGFRkiRJkhRiWJQkSZIkhRgWJUmSJEkhhkVJkiRJUohhUZIkSZIUYliUJEmSJIUYFiVJkiRJIYZFSZIkSVKIYVGSJEmSFGJYlCRJkiSFGBYlSZIkSSGGRUmSJElSiGFRkiRJkhRiWJQkSZIkhRgWJUmSJEkhhkVJkiRJUohhUZIkSZIUYliUJEmSJIUYFiVJkiRJIYZFSZIkSVKIYVGSJEmSFGJYlCRJkiSFGBYlSZIkSSGGRUmSJElSiGFRkiRJkhSSV1hMpoK7kqmge472rslUcFfhy5IkSZIkFVO+M4tnAV1ytHfJ9kmSJEmS2pF8w2IESDdvSKaCCDAaWFrooiRJkiRJxVXeWmcyFTSSCYlpYEkyFeQ67IY2qEuSJEmSVESthkXgDDKzin8BxgKrmvXVAvMS8diUNqpNkiRJklQkrYbFRDz2fwDJVPAu8GIiHqvbIVVJkiRJkopqSzOLACTisecAkqmgEoix2b2OiXhsYeFLkyRJkiQVS15hMZkK9gbuAg4msyx1o40b35QVvjRJkiRJUrHkFRaBO4GuwFeAxWy2M6okSZIkqX3JNyyOAEYl4rFUWxYjSZIkSSoN+T5n8V1caipJkiRJHUa+YfFi4MpkKqhqy2IkSZIkSaUh32Wo1wG7A0uSqWAxmWcsNknEY/sUujBJkiRJUvHkGxbvadMqJEmSJEklJd/nLP6yrQuRJEmSJJWOfO9ZlCRJkiR1IHnNLCZTQSOtPFsxEY+5U6okSZIktSP53rN4JpuGxQpgGHAq4BJVSZIkSWpn8r1nMdcGN3cnU8EM4FDgDwWtSpIkSZJUVNt7z+LTwLGFKESSJEmSVDq2NyyOAVYVohBJkiRJUunId4Obf2/WFAH6AR8Ffl7ooiRJkiRJxZXvBjeLNnvdCEwBLkjEY08VtiRJkiRJUrHlu8HNN9q6EEmSJElS6ch3ZhGAZCoYAOyXfTkzEY+9V/iSJEmSJEnFlu89i7uQeTzG18jcrwjQmEwF9wDnJeKx9W1UnyRJkiSpCPLdDfVa4HPAiUDv7NfJZJ6xeG2bVCZJkiRJKpp8l6GeApyZiMeeaNb2cDIV1AB/BsYWvDJJkiRJUtHkO7PYE5iXo30e0KNw5UiSJEmSSkG+YfF14Jwc7edm+yRJkiRJ7Ui+y1AvIbPsdDQwMdv2GSABHNcWhUmSJEmSiievmcVEPPZPYBgwCzg8+zULGJaIx/7VduVJkiRJkooh7+csJuKx14Az27AWSZIkSVKJyGtmMZkKjk6mgjE52sfkapckSZIk7dzy3eDmSqAiR3sZcFXhypEkSZIklYJ8w+JQcu96OjPbJ0mSJElqR/K9Z3ED8BHCz1rsB9QVsqBkKvgicDmwL7AGuC4Rj12bTAXlwHXAGWRC7jjg/EQ8tiH7vlb7JUmSJEn5y3dm8Rngl8lU0HljQzIVdAEuBZ4uVDHJVHAkcDvwI6AnsA/weLb7p8ChQJzMbOZ+wDXN3r6lfkmSJElSnvKdWbwIeBF4J5kKXsy2fZpM2BxdwHouBy5PxGNPZV+v5r/LX78NXJSIxxYBJFPBpcA/kqngwkQ81pBHvyRJkiQpT3mFxUQ89k4yFXwKGAskss13Arck4rElhSgkmQq6AiOAx5Op4C2gN/AK8D1gJTAAmN78LUB3YFAyFSxvrR+Y29J1I5EIkUi+E6w71sa6SrU+7RwcRyoUx1LHkU6X5Wwv1O/esaRCcBypUDryWIpEIq32b81zFj8A/nd7C2pFbyACnAyMAQLgd8CDwHHZY6qbHb/x++5A7Rb6W9RvzyE0NJT2xGO/QUOKXYLaAceRCsWx1P5tqM7d3n9wYa/jWFIhOI5UKB1xLJWV5f7HwY3yDos7wJrsnzck4rH5AMlU8FNgKZkQCZn7GDfOZPZq9r41W+hv0eIFc6ivK+gePQUTiUTpN2gIi+fPIZ1uLHY52kk5jlQojqWOY+8D1uVsnzuta0HO71hSITiOVCgdeSyVV1SQGN7yXYUlExYT8diqZCpYAKRbOORdYH/g7ezrA8gEwfmJeKwhmQpa7G/tuul0uuQHRTrdWPI1qvQ5jlQojqX2LxLJveKm0L93x5IKwXGkQumIYymdbil6ZZRMWMy6FfheMhX8m8yM4uXA1EQ8tjCZCu4EfpJMBc+TeVzHpcDdzTav2VK/JEmSJClPpRYWryFz72KSzE6rk4CTsn1XAn2Bmdm+B4CLm713S/2SJEmSpDxtdVhMpoI+wIpEPNb6nOU2SMRjjWQCXijkJeKxeuCC7Feu97baL0mSJEnKX15hMZkKyoBLyASx7sA+ZJ65eDUwLxGP3dZ2JUqSJEmSdrR8HyZyMXAWmbBY26x9GvD1AtckSZIkSSqyfMPiWcB3EvHYX4HmG8akyMwySpIkSZLakXzD4kDgzRzt9UCXwpUjSZIkSSoF+YbF+cCncrQfAbxVsGokSZIkSSUh391QbwFuSKaCDdnXQ5OpYAyZx1X8oE0qkyRJkiQVTV5hMRGP3Zh9ZMZ4MstOHwc2AFcm4rG72rA+SZIkSVIR5LsMlUQ8dimZh96PBA4Cdk3EY79qo7okSZIkSUWU7zJUABLx2HpgShvVIkmSJEkqEXmFxWQqeLq1/kQ8dlhhypEkSZIklYJ8Zxbnbva6AjgA2BO4v6AVSZIkSZKKLt8Nbs7O1Z5MBdcD1QWtSJIkSZJUdHlvcNOCW4HvFqIQSZIkSVLp2N6wuCeZJamSJEmSpHYk3w1ufrpZUwToB5wOTCh0UZIkSZKk4sp3g5vN71lsBALgD8CvC1qRJEmSJKno8t3gZnBbFyJJkiRJKh3be8+iJEmSJKkdyveexdvzPWEiHjtn28uRJEmSJJWCfO9ZHAokyOx8+na2bV+gFpjW7Lh04UqTJEmSJBVLvmFxHFAHfCURjy0DSKaCvsA9wGOJeOzGNqpPkiRJklQE+d6z+CPg/20MigDZ73+c7ZMkSZIktSP5hsVdgcoc7RVA38KVI0mSJEkqBfmGxYnAzclUsPfGhuz3v8/2SZIkSZLakXzvWTwHeAiYlUwFG5ei9gVeA05vi8IkSZIkScWTV1hMxGMLgUQyFRwBfCzb/EYiHnuqzSqTJEmSJBVNvjOLACTisSeBJ9uoFkmSJElSiWgxLCZTwVeABxLxWG32+xYl4rF7C16ZJEmSJKloWptZvIfMLGKQ/b4lacCwKEmSJEntSIthMRGPRXN9L0mSJElq/wyBkiRJkqSQvDe4SaaCnsBIYDc2C5mJeOwvBa5LkiRJklREeYXFZCoYA9wH9AAaNutOA4ZFSZIkSWpH8p1ZvA54EPhxIh4L2rAeSZIkSVIJyDcsDgKOMyhKkiRJUseQ7wY3U4C92rIQSZIkSVLpyHdm8XLg2mQquBSYAdQ270zEY4sLXJckSZIkqYjyDYv/zv45nsyGNhtFsq/LClmUJEmSJKm48g2Lh7ZpFZIkSZKkkpJXWEzEY8+1dSGSJEmSpNLRalhMpoJPt9C1AZiTiMdWF74kSZIkSVKxbWlmcRKZexIjOfrqk6ngLuD8RDzWUPDKJEmSJElFs6WwOLiF9l7AgcBlwNvAbwtZlCRJkiSpuFoNi4l4bEELXQuAGclUsAb4MYZFSZIkSWpXotv5/leAvQpRiCRJkiSpdGxvWOwFrCpEIZIkSZKk0rHNYTGZCiLABcDUwpUjSZIkSSoFW3p0xu0tdPUEhgG7AS09XkOSJEmStJPa0m6oQ1toXwU8ANySiMcWFrYkSZIkSVKxbWk31EN3VCGSJEmSpNKxvRvcSJIkSZLaIcOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCikvdgG5JFNBFyAFfCQRj3XLtpUD1wFnkAm544DzE/HYhnz6JUmSJEn5K9WZxcuABZu1/RQ4FIgDQ4H9gGu2ol+SJEmSlKeSm1lMpoJhwBjgh8CDzbq+DVyUiMcWZY+7FPhHMhVcmIjHGvLozykSiRCJlGZm3lhXqdannYPjSIXiWOo40umynO2F+t07llQIjiMVSkceS5FIpNX+kgqL2aWkdwDn02zWM5kKegEDgOnNDwe6A4OSqWB5a/3A3Jau2W/PITQ0tJglS0K/QUOKXYLaAceRCsWx1P5tqM7d3n9wYa/jWFIhOI5UKB1xLJWV5f7HwY1KKiwCPwKmJeKxiclU8Llm7d2zfzb/66u6WV/tFvpbtHjBHOrr6rat2jYWiUTpN2gIi+fPIZ1uLHY52kk5jlQojqWOY+8D1uVsnzuta0HO71hSITiOVCgdeSyVV1SQGD665f4dWEurkqlgCPAd4IAc3Wuyf/YElmS/79Wsb0v9LUqn0yU/KNLpxpKvUaXPcaRCcSy1f5FI7hU3hf69O5ZUCI4jFUpHHEvpdLrV/lJamDsa2A2YlUwFy4CHga7Z7z8JvAvs3+z4A8gEwfmJeKy6tf62L12SJEmS2peSmVkE7geebPZ6FHA3mQC4FLgT+EkyFTwP1AGXAnc327xmS/2SJEmSpDyVTFhMxGMfAh9ufJ1MBUuBdCIeey/7+kqgLzCTzIzoA8DFzU6xpX5JkiRJUp5KJixuLhGPPQt0a/a6Hrgg+5Xr+Fb7JUmSJEn5K9mwKEmS2kbDXifmbC97Z/wOrkSSVMpKaYMbSZIkSVKJMCxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkLKi12AJEkqLcOWVeZsn72D65AkFZczi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkEMOiJEmSJCnEsChJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQgyLkiRJkqQQw6IkSZIkKcSwKEmSJEkKMSxKkiRJkkIMi5IkSZKkkPJiF7BRMhV0Am4CDgd2Bd4HbkzEYzdm+8uB64AzyITcccD5iXhsQz79kiRJkqT8ldLMYjmwBDgS6AmcBvw8mQpOy/b/FDgUiANDgf2Aa5q9f0v9kiRJkqQ8lczMYiIeWwf8b7Om6clU8AgwGrgf+DZwUSIeWwSQTAWXAv9IpoILE/FYQx79OUUiESKRUsrM/7WxrlKtTzsHx5EKxbHUfkTI/dfixt9tfQv/llyo371jSYXgOFKhdOSxFIlEWu0vmbC4uWQqqAAOAX6TTAW9gAHA9OaHAN2BQclUsLy1fmBuS9fpt+cQGhpazJIlod+gIcUuQe2A40iF4lhqD2blbh68DwAvt/Cu/oMLW4VjSYXgOFKhdMSxVFZW1mp/yYZFMvcvrgH+AuyWbatu1r/x++5A7Rb6W7R4wRzq6+q2r9I2EolE6TdoCIvnzyGdbix2OdpJOY5UKI6l9qNh8DE528vmTQDg5IG1OfvHLawsyPUdSyoEx5EKpSOPpfKKChLDR7fcvwNryVsyFVwPjAIOS8RjtclUsCbb1ZPMfY0AvbJ/rsl+tdbfonQ6XfKDIp1uLPkaVfocRyoUx9LOL03uf0ne+HstJ/fvt9C/d8eSCsFxpELpiGMpnU632l9yYTGZCn5HZkfUwxLx2DKARDxWnUwF7wL7A29nDz2ATBCcn4jHGlrr34HlS5J2gKHD1uZsnz212w6uRJKk9qukwmIyFfweOAw4NBGPLd2s+07gJ8lU8DxQB1wK3N1s85ot9UuSJEmS8lQyYTGZCvYE/geoAeYlU8HGrucT8dhRwJVAX2AmmUd+PABc3OwUW+qXJEmSJOWpZMJiIh5bALS4d2siHqsHLsh+bXW/JEmSJCl/He9hIpIkSZKkLTIsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQkrm0RmSJEmS8jN02Nqc7bOndtvBlag9c2ZRkiRJkhRiWJQkSZIkhRgWJUmSJEkhhkVJkiRJUohhUZIkSZIUYliUJEmSJIUYFiVJkiRJIYZFSZIkSVKIYVGSJEmSFGJYlCRJkiSFGBYlSZIkSSGGRUmSJElSiGFRkiRJkhRiWJQkSZIkhRgWJUmSJEkhhkVJkiRJUohhUZIkSZIUUl7sAiRJkiSFNex1Ys72snfG7+BK1FEZFiVJUknzP5glqThchipJkiRJCjEsSpIkSZJCDIuSJEmSpBDDoiRJkiQpxLAoSZIkSQoxLEqSJEmSQnx0hiSp5PioBEmSis+ZRUmSJElSiGFRkiRJkhTiMlRJkiRJRZXr9gNvPSg+ZxYlSZIkSSGGRUmSJElSiGFRkiRJkhRiWJQkSZIkhbjBjSRJUgH5nFBJ7YVhUZIkSdrJDFtWmbN99g6uQ+2bYVGSJEnaAh/toI7IsChJktotl4RK0rYzLEqSdjouv5Ikqe25G6okSZIkKcSZRUk7PZeZSZIkFZ4zi5IkSZKkEGcWJUkdxtBha3O2z57abQdXIklS6XNmUZIkSZIUYliUJEn6/+3dX4gdVwHH8e/N/im2TbvVdvwDbbI0WiycYE/tQ6Eisdi/EUGlD0LAhxaEaEShqUYtxUDA2FRtiw9WtPggQlvR+FBFBWn6IpSxOC2U1JLUpiiTaLaNTdPGzfpwZvWy9+7eP/vnzr37/bzc3Tl7ds5efntmzpyZcyVJLRwsSpIkSZJa+MxiDc2v7NhgFjjM7PR25hhzZUdJ6oKr40qStDKcWZQkSZIktXBmUVILZ2Ykyb5QkhwsShppflSCJElSfxwsSpKkdcmLScvn7Ks02hwsSmvAg6nWK7Mv1Z//p5IW4wI3kiRJkqQWzixqKHkVVJLsCyVJq8uZRUmSJElSC2cWpRE1P+PQYBY4zOz0duYYq+2MgzMkWq+GLfvD1t5h4/srqU4cLGpgPCBKktYjV2HVqPLcbvQ4WJQkqeKJjqSVNmz9yrC1V6trpAaLeVGOAweAHaTnMZ8AdsaQnRlow6RlGLZOe9jaK0laHXWcQfUYJfVmpAaLwB5gGxCAt4GDwH5g1yAbtZbadYLddIB2nlqvzL60dur2LPW1Jybbbn9xjduxXvV7zqLu+P52Vrc+qY5GbbB4J7A7huxVgLwo7wMey4vyyzFks+0qTExM0mg01rCJnW0YOwdAg3OMMcYE55ijwdjkeV3XbdZvvW7r9ms5+1xO3dlNt7Sv+/JvVqUeDOZvXekcdbPP5dRdrX02Gm3/9Zmofm+/+11OHgZVt1/z+2wwyxhH2LDltnQwXcXsd6p3dqz9Yt4TkxNDl4c6/r/1+/520m+/tFrv0VJ/53L226ne1pPt93t0me9vvzmsU//by9+5ln3SYnUHeUztJ7+DbO/01tNty4785fxF665m7pv32c+50qgYH59YsrwxNze3Rk1ZXXlRTgEngQ/GkL1QbbsMKIEtMWQvNf/8/kd+eznwtzVvqCRJkiTVyxW777r5lYUbR2lmcWP1OtO0bWZBWbNjwBXA66vZKEmSJEmqsYtIY6MWozRYPFW9Xgz8o/p6akHZ/+y+6+Y5oGX0LEmSJEnryGuLFbS/2XkIxZDNkAZ/H2rafA1poHh0EG2SJEmSpGE1SjOLAD8CvpYX5SHgLHAf8Ohii9tIkiRJktobtcHiPuBS4HnSrOnjwD0DbZEkSZIkDaGRWQ1VkiRJkrRyRuaZRUmSJEnSyhm121BHRl6U48ABYAdpUP8EsDOG7MxAG6bayovyPOBh4EbgMuDvwEMxZA9V5WZKPcuL8h1AAbwnhuzCaptZUtfyorwd2AtcRVp07kAM2XfMkXqRF+V7Sce4jwIN4BDwhRiyY2ZJi8mL8g5gF2kBzBMxZJubypbMjblKnFmsrz3ANiAA7weuBvYPtEWqu3HSx8bcRPoImTuAb1QdJZgp9edbwMsLtpkldSUvypuAHwJ3k/qlDwBPVsXmSL34ATAJTAOXA28AP67KzJIWc5J0keHrbco65cZc4WCxzu4E9sWQvRpDdpy0suvn8qIcG2yzVFcxZG/EkH0zhuyvMWTnYsieBQ4CN1Q/YqbUk7worwVuAb69oMgsqVt7gb0xZH+IIftPDNnrMWTPVWXmSL24EngshuxUDNlp4GfA1qrMLKmtGLLfxZD9nNaLntA5N+YKb0Otpbwop0hXzZ5t3gxsBDYDLw2gWRoyeVFOAB8B7jdT6lV1+80jwE6aLiyaJXUrL8oLgOuAJ/OifAG4BPgT8CXS1X5zpF48AHwmL8qDwCzp1sBf2yepH51ykxflP5cqZx3lypnFetpYvc40bZtZUCZ18jDp+aCfYqbUu7uBP8eQPbVgu1lSty4hPVv2adIM9TTpVvlfYI7Uu6eBKeBfpKxcRbpN0CypH51yY64qDhbr6VT1enHTtqkFZdKi8qJ8ALgeuDWG7G3MlHqQF+UW4POkAeNCZkndms/D92PIjla3Du4hLTTRqMrMkTrKi3ID8HvgGeAi4ELgl8AfgfnFRsySetHpWOaxruJgsYZiyGaAV0gH1HnXkMJ5dBBt0vDIi/J7wMeBG2PIToCZUs9uAN4NHM6L8gTwK+CC6uutmCV1IYbsNdJzQot9oLM5UrfeCWwCHowh+3cM2Zuk21KvBt6FWVKPOp0Xed70f425ucX6cA1SXpT3Ap8CbgPOkk7Wnokh2zXQhqnW8qJ8EPgYsK16GLu5zEypK3lRnk86OZt3PfAo6bav48A9mCV1IS/KrwKfBW4nZee7wHUxZB+2T1Iv8qJ8kTSbeC/pmcXdwFeA91VfmyW1qBajmQA+AdxPOo7NxZC91akPso9KXOCmvvYBlwLPk2aAHyedoElt5UW5Cfgi8BZwJC/K+aJDMWS3YqbUpep2wdPz3+dFeZx0cD1WfW+W1K39pGcXc1JWniadfIF9knrzSdJs4jFSXp4DtseQnbFP0hJ2AD9p+v5N0h0Pm+ncB5krnFmUJEmSJLXhM4uSJEmSpBYOFiVJkiRJLRwsSpIkSZJaOFiUJEmSJLVwsChJkiRJauFgUZIkSZLUwsGiJEmSJKmFg0VJkiRJUov/Ajkg+FJNDgjjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4abf587518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15,8))\n",
    "plt.bar(yPosition, pod, alpha=0.7, label='Appeared')\n",
    "plt.bar(yPosition, podp, alpha=0.5, label='Predicted')\n",
    "plt.bar(yPosition, podc, alpha=0.5, label='Correctly Predicted')\n",
    "\n",
    "plt.ylabel('Unique count')\n",
    "plt.title('Categories')\n",
    "plt.legend()\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
