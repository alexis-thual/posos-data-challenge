{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Workflow Notebook\n",
    "This notebook is intended to present models which are loaded from other files as well as the results they allow us to reach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Global variables and imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import gensim\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from keras.models import Model\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing import sequence, text\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_CATEGORIES = 52\n",
    "BATCHSIZE = 32\n",
    "\n",
    "dataFolder = './../posos-data-challenge/challenge_data'\n",
    "xPath = os.path.join(dataFolder, 'input_train.csv')\n",
    "yPath = os.path.join(\n",
    "    dataFolder, 'challenge_output_data_training_file_predict_the_expected_answer.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel():\n",
    "    '''Generic workflow class.'''\n",
    "\n",
    "    def __init__(self, **kwargs):\n",
    "        self.verbose = kwargs.get('verbose', False)\n",
    "\n",
    "        self.nbCategories = kwargs['nbCategories']\n",
    "        self.paddingLength = PADDING\n",
    "        self.maxNumberWords = (1e5)\n",
    "        self.trainable = kwargs.get('trainable', False)\n",
    "\n",
    "        self.tokenizer = text.Tokenizer(num_words=self.maxNumberWords)\n",
    "\n",
    "    def preprocess(self, x):\n",
    "        '''Turns sentences into padded word sequences.'''\n",
    "\n",
    "        self.tokenizer.fit_on_texts(x)\n",
    "        sequences = self.tokenizer.texts_to_sequences(x)\n",
    "        sequences = sequence.pad_sequences(sequences, self.paddingLength)\n",
    "\n",
    "        return sequences\n",
    "\n",
    "    def preprocessLabels(self, labels):\n",
    "        return to_categorical(labels, num_classes=self.nbCategories)\n",
    "\n",
    "    def train(self, x, y, epochs=5, batch_size=BATCHSIZE, validation_data=None,\n",
    "              callback=False):\n",
    "        if callback == True:\n",
    "            filepath= 'models_checkpoints/weights-improvement-{epoch:02d}-{val_acc:.2f}.hdf5'\n",
    "            checkpoint = ModelCheckpoint(filepath, monitor='val_acc',\n",
    "                                         verbose=1, save_best_only=True, mode='max')\n",
    "            callbacks_list = [checkpoint]\n",
    "\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data,\n",
    "                           callbacks=callbacks_list)\n",
    "        else:\n",
    "            self.model.fit(x, y, shuffle='batch', epochs=epochs,\n",
    "                           batch_size=batch_size, validation_data=validation_data)\n",
    "\n",
    "    def evaluate(self, x, y):\n",
    "        return self.model.evaluate(x, y)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customize generic workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform spelling corrections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "correctionsPath = os.path.join(dataFolder, 'corrections.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def spellingCorrection(self, x, correct_dict={}, verbose=False):\n",
    "        corrected_x = []\n",
    "        for w in x.split():\n",
    "            if w in correct_dict.keys():\n",
    "                w_corrected = corrected_dict[w]\n",
    "                if verbose == True:\n",
    "                    print('Correction of ' + w + ' in ' + w_corrected)\n",
    "                w = w_corrected\n",
    "            corrected_x.append(w)\n",
    "        return ' '.join(corrected_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Differenciate medics from other words\n",
    "We here use a list of medication names to distinguish better between common words and specialized ones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Liste de médicaments regroupant les libéllés ATC et lesdénominations de spécialité, de taille: 8275\n",
      "Sample of medicament names:  ['ubistesin adrenalinee', 'forene,', 'sevorane,', 'chirocaïne', 'duodopa', 'synagis', 'kaletra', 'humira', 'norvir', 'viekirax']\n"
     ]
    }
   ],
   "source": [
    "MEDICAMENTS = []\n",
    "medicsPath = os.path.join(dataFolder, 'medicaments_france.xls')\n",
    "medic_db = pd.read_excel(medicsPath)\n",
    "\n",
    "for m in medic_db['Dénomination spécialité']:\n",
    "    med = []\n",
    "    for w in m.split():\n",
    "        if w.lower()!=w:\n",
    "            med.append(w)\n",
    "    med = ' '.join(med)\n",
    "    if len(med)!=0:\n",
    "        med = med.lower()\n",
    "        if med not in MEDICAMENTS:\n",
    "            MEDICAMENTS.append(med.lower())\n",
    "\n",
    "for m in medic_db['Libellé ATC']:\n",
    "    med = m.split()[0].lower()\n",
    "    if med not in MEDICAMENTS:\n",
    "        MEDICAMENTS.append(med)\n",
    "\n",
    "print('Liste de médicaments regroupant les libéllés ATC et les'\n",
    "      'dénominations de spécialité, de taille: {}'.format(len(MEDICAMENTS)))\n",
    "print('Sample of medicament names: ', MEDICAMENTS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.medicaments = kwargs['medicaments']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Designing the Model itself"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import (Input, Conv1D, Dense, Dropout,\n",
    "                          GlobalMaxPooling1D)\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "\n",
    "    def buildCNN(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=4):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = keras.Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = (Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding'))(my_input)\n",
    "\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop1')(embedding)\n",
    "\n",
    "        conv1 = Conv1D(nb_filters, filter_size,\n",
    "                      activation='relu', name='conv1')(embedding_dropped)\n",
    "        pooled_conv1 = GlobalMaxPooling1D(name='pool1')(conv1)\n",
    "        pooled_conv_dropped1 = Dropout(drop_rate, name='drop2')(pooled_conv1)\n",
    "        dense1 = Dense(100, activation='relu', name='dense1')(pooled_conv_dropped1)\n",
    "        dropout2 = Dropout(drop_rate, name='drop3')(dense1)\n",
    "        prob = Dense(self.nbCategories,\n",
    "                     activation='softmax', name='dense2')(dropout2)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import MaxPooling1D, LSTM\n",
    "\n",
    "class CustomModel(CustomModel):\n",
    "    '''Extended CustomModel'''\n",
    "    \n",
    "    def buildLSTM(self, embedding, drop_rate=0.3, nb_filters=128, filter_size=4):\n",
    "        self.embedding = embedding\n",
    "\n",
    "        my_input = keras.Input(shape=(self.paddingLength,), name= 'input')\n",
    "\n",
    "        embedding = (Embedding(input_dim=self.embedding.shape[0],\n",
    "                               output_dim=self.embedding.shape[1],\n",
    "                               weights=[self.embedding],\n",
    "                               input_length=self.paddingLength,\n",
    "                               trainable=self.trainable,\n",
    "                               name='embedding'))(my_input)\n",
    "\n",
    "        embedding_dropped = Dropout(drop_rate, name='drop1')(embedding)\n",
    "\n",
    "        conv1 = Conv1D(nb_filters, filter_size,\n",
    "                      activation='relu', name='conv1', padding = 'same')(embedding_dropped)\n",
    "        pooled_conv1 = MaxPooling1D(pool_size = 2, name = 'pool1')(conv1)\n",
    "        dropped1 = Dropout(drop_rate, name = 'drop1')(pooled_conv1)\n",
    "        lstm1 = LSTM(100, name = 'lstm1')(dropped1)\n",
    "        prob = Dense(self.nbCategories,\n",
    "                     activation='softmax', name='dense2')(lstm1)\n",
    "\n",
    "        self.model = Model(my_input, prob)\n",
    "\n",
    "        self.model.compile(\n",
    "            loss='categorical_crossentropy',\n",
    "            optimizer='adam',\n",
    "            metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model variables\n",
    "TRAINABLE = False # never train the embedding for the classification task; it leads to overfitting\n",
    "PADDING = 150\n",
    "EPOCHS = 10\n",
    "PRE_TRAINED_DIM = 300 # Size of the pretrained embedding used here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model instance creation\n",
    "model = CustomModel(nbCategories=NB_CATEGORIES, trainable=TRAINABLE, medicaments=MEDICAMENTS)\n",
    "\n",
    "# Loading, parsing and spliting training and testing data\n",
    "x = pd.read_csv(xPath, delimiter=';', usecols=[1]).values.ravel()\n",
    "y = pd.read_csv(yPath, delimiter=';', usecols=[1]).values.ravel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct spelling mistakes\n",
    "corrected_dict = {}\n",
    "for key, val in csv.reader(open(correctionsPath)):\n",
    "    corrected_dict[key] = val\n",
    "for i, s in enumerate(x):\n",
    "    x[i] = model.spellingCorrection(s, corrected_dict, verbose = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary size:  10141\n"
     ]
    }
   ],
   "source": [
    "# Print some info about our vocabulary\n",
    "model.preprocess(x)\n",
    "x_vocab  = list(model.tokenizer.word_index.keys())\n",
    "print('Vocabulary size: ', len(x_vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------- Embedding Created ----------\n",
      "Number of words in corpus that do not appear in pretrained Fasttext:  2760\n"
     ]
    }
   ],
   "source": [
    "# Loading and using pretrained embedding\n",
    "\n",
    "# Using fasttext\n",
    "path2embedding = './../wiki.fr.vec'\n",
    "pre_trained_wv = gensim.models.KeyedVectors.load_word2vec_format(path2embedding,\n",
    "                                                                 binary=False)\n",
    "\n",
    "# We use an embedding size of len(x_vocab) + 1 because the 0 is used for the padding\n",
    "embeddings = np.zeros((len(x_vocab) + 1 , PRE_TRAINED_DIM))\n",
    "not_in_pretrained = []\n",
    "\n",
    "for word, idx in model.tokenizer.word_index.items():\n",
    "    if word not in pre_trained_wv.vocab:\n",
    "        vec = np.zeros(PRE_TRAINED_DIM)\n",
    "        not_in_pretrained.append(word)\n",
    "    else:\n",
    "        vec = pre_trained_wv[word]\n",
    "\n",
    "    # word_to_index is 1-based! the 0-th row, used for padding, stays at zero\n",
    "    embeddings[idx,] = vec\n",
    "\n",
    "print('---------- Embedding Created ----------')\n",
    "print('Number of words in corpus that do not appear in '\n",
    "      'pretrained Fasttext: ', len(not_in_pretrained))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the embedding for convenience\n",
    "#np.save('challenge_data/fasttext_emb.npy', embeddings)\n",
    "embeddings = np.load('challenge_data/fasttext_emb.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input (InputLayer)           (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 300)          3042600   \n",
      "_________________________________________________________________\n",
      "drop1 (Dropout)              (None, 150, 300)          0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv1D)               (None, 150, 32)           28832     \n",
      "_________________________________________________________________\n",
      "pool1 (MaxPooling1D)         (None, 75, 32)            0         \n",
      "_________________________________________________________________\n",
      "lstm1 (LSTM)                 (None, 100)               53200     \n",
      "_________________________________________________________________\n",
      "dense2 (Dense)               (None, 52)                5252      \n",
      "=================================================================\n",
      "Total params: 3,129,884\n",
      "Trainable params: 87,284\n",
      "Non-trainable params: 3,042,600\n",
      "_________________________________________________________________\n",
      "Total number of model parameters: 3129884\n"
     ]
    }
   ],
   "source": [
    "# Model parameters among (drop_rate=0.3, nb_filters=32, filter_size=3)\n",
    "DROP_RATE = 0.3\n",
    "NB_FILTERS = 32\n",
    "FILTER_SIZE = 3\n",
    "\n",
    "# Build our model\n",
    "model.buildLSTM(embeddings, drop_rate=DROP_RATE,\n",
    "                 nb_filters=NB_FILTERS, filter_size=FILTER_SIZE)\n",
    "model.model.summary()\n",
    "\n",
    "print('Total number of model parameters:', model.model.count_params())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess input data and labels before training\n",
    "y = model.preprocessLabels(y)\n",
    "\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "xTrain = model.preprocess(xTrain)\n",
    "xTest = model.preprocess(xTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 6422 samples, validate on 1606 samples\n",
      "Epoch 1/10\n",
      "6422/6422 [==============================] - 20s 3ms/step - loss: 3.1590 - acc: 0.2362 - val_loss: 2.9277 - val_acc: 0.2914\n",
      "Epoch 2/10\n",
      "6422/6422 [==============================] - 22s 3ms/step - loss: 2.7872 - acc: 0.3085 - val_loss: 2.8070 - val_acc: 0.3064\n",
      "Epoch 3/10\n",
      "6422/6422 [==============================] - 27s 4ms/step - loss: 2.5445 - acc: 0.3594 - val_loss: 2.7275 - val_acc: 0.3325\n",
      "Epoch 4/10\n",
      "6422/6422 [==============================] - 24s 4ms/step - loss: 2.3526 - acc: 0.4050 - val_loss: 2.7290 - val_acc: 0.3294\n",
      "Epoch 5/10\n",
      "6422/6422 [==============================] - 24s 4ms/step - loss: 2.1905 - acc: 0.4408 - val_loss: 2.7738 - val_acc: 0.3088\n",
      "Epoch 6/10\n",
      "6422/6422 [==============================] - 26s 4ms/step - loss: 2.0705 - acc: 0.4637 - val_loss: 2.7450 - val_acc: 0.3288\n",
      "Epoch 7/10\n",
      "6422/6422 [==============================] - 27s 4ms/step - loss: 1.9517 - acc: 0.4947 - val_loss: 2.7618 - val_acc: 0.3144\n",
      "Epoch 8/10\n",
      "6422/6422 [==============================] - 26s 4ms/step - loss: 1.8854 - acc: 0.5073 - val_loss: 2.7599 - val_acc: 0.3369\n",
      "Epoch 9/10\n",
      "6422/6422 [==============================] - 26s 4ms/step - loss: 1.7966 - acc: 0.5268 - val_loss: 2.8742 - val_acc: 0.2970\n",
      "Epoch 10/10\n",
      "6422/6422 [==============================] - 27s 4ms/step - loss: 1.7280 - acc: 0.5385 - val_loss: 2.9579 - val_acc: 0.2839\n"
     ]
    }
   ],
   "source": [
    "# Training\n",
    "model.train(xTrain, yTrain, epochs=EPOCHS, validation_data=(xTest, yTest))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1606/1606 [==============================] - 0s 141us/step\n",
      "Accuracy: 32.19 %\n",
      "Loss: [2.8074336494336536, 0.32191780821917809]\n"
     ]
    }
   ],
   "source": [
    "loss = model.evaluate(xTest, yTest)\n",
    "\n",
    "prediction = model.predict(xTest)\n",
    "predictionCategories = np.argmax(prediction, axis=1)\n",
    "yTestCategories = np.argmax(yTest, axis=1)\n",
    "accuracy = 100 * sum([predictionCategories[i] == yTestCategories[i]\n",
    "                      for i in range(len(yTestCategories))]) / len(yTestCategories)\n",
    "\n",
    "print('Accuracy: {:.2f} %\\nLoss: {}'.format(accuracy, str(loss)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAEyCAYAAACLaSO4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nRK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fabdc605c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.hist(y, bins=NB_CATEGORIES, label='train labels', density=True, alpha=0.6)\n",
    "plt.hist(predictionCategories, bins=NB_CATEGORIES,\n",
    "         label='predicted labels', density=True, alpha=0.6)\n",
    "\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([37, 44, 44, ..., 48, 45, 44])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yTestCategories"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
